#!/usr/bin/env python3
""" covid19-vi  -  Visualization utilities for the COVID-19 data from Johns Hopkins.

    The *covid19-vi* utility is the main interface for the projects access to the public COVID-19
    time series data.  The *--download* option is used to retrieve the latest data from the
    sources defined in the project. The data is read with a url request and loaded into a
    dataframe.  The dataframe is processed with error checkers, aggretators, and analytics
    utilities and then pickled for quicker use by the utility.

    Copyright (C) 2020  Natalya Langford

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""
__author__ = 'Natalya Langford'
__copyright__ = 'Copyright (C) 2020 Natalya Langford'
__credits__ = ['Ricks-Lab - Collaborator']
__license__ = 'GNU General Public License'
__program_name__ = 'covid19-vi'
__version__ = 'v0.0.1'
__maintainer__ = 'Natalya Langford'
__status__ = 'Under Development'
__docformat__ = 'reStructuredText'
# pylint: disable=multiple-statements
# pylint: disable=line-too-long

import argparse
import sys
import re
import os
from datetime import datetime
import io
import pickle
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.ticker import FormatStrFormatter
import us_state_abbrev as ussa
import covid19_math as cm


class CovidData:
    """
    Class for downloading, processing, and reporting on COVID-19 time series data.
    """
    # Define possible data sources.
    _covid_data_global_jhu = {
        'confirmed': {'url': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',
                      'src_link': 'https://github.com/CSSEGISandData/COVID-19',
                      'src_name': 'Johns Hopkins University',
                      'src_key': 'jhu',
                      'header_cols': 4,
                      'summary_cols': 0},
           'deaths': {'url': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv',
                      'src_link': 'https://github.com/CSSEGISandData/COVID-19',
                      'src_name': 'Johns Hopkins University',
                      'src_key': 'jhu',
                      'header_cols': 4,
                      'summary_cols': 0}}
    _covid_data_usa_jhu = {
        'confirmed': {'url': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv',
                      'src_link': 'https://github.com/CSSEGISandData/COVID-19',
                      'src_name': 'Johns Hopkins University',
                      'src_key': 'jhu',
                      'header_cols': 11,
                      'summary_cols': 0},
           'deaths': {'url': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv',
                      'src_link': 'https://github.com/CSSEGISandData/COVID-19',
                      'src_name': 'Johns Hopkins University',
                      'src_key': 'jhu',
                      'header_cols': 12,
                      'summary_cols': 0}}
    _covid_data_usa_usf = {
        'confirmed': {'url': 'https://static.usafacts.org/public/data/covid-19/covid_confirmed_usafacts.csv',
                      'src_link': 'https://usafacts.org/issues/coronavirus/',
                      'src_name': 'USA Facts',
                      'src_key': 'usf',
                      'header_cols': 4,
                      'summary_cols': 0},
           'deaths': {'url': 'https://static.usafacts.org/public/data/covid-19/covid_deaths_usafacts.csv',
                      'src_link': 'https://usafacts.org/issues/coronavirus/',
                      'src_name': 'USA Facts',
                      'src_key': 'usf',
                      'header_cols': 4,
                      'summary_cols': 0}}
    # Choose which data sources are to be used.
    _covid_data = {'global': _covid_data_global_jhu, 'usa': _covid_data_usa_jhu}

    _pickle_filename = 'covid_data.pickle'
    _prov_state_countries = ['China', 'Canada', 'Australia', 'France', 'United Kingdom', 'Netherlands', 'Denmark']
    _analytics_source = 'https://github.com/natalyalangford/COVID19_plots'
    _valid_args = {'type': ['deaths', 'confirmed'],
                   'region': ['country', 'state', 'province', 'county', 'county-state'],
                   'response': ['log', 'linear', 'new-total', 'trajectory', 'rdtd']}

    def __init__(self, args, download=False):
        """
        Initialize a CovidData object and populate from interweb if download is True.
        :param download: Flag to force actual download instead of using pickled data.
        :type download: Bool
        :return None
        """
        null_df = pd.DataFrame()                           # Used to initialize data so type checking works.
        self.data = {'global': {'data_date': None,         # Date of the last day of time series.
                                'download_date': None,     # Date of data download.
                                'summary_cols': 0,         # Number of summary columns in df.
                                'header_cols': 0,          # Number of header columns in df.
                                'src_name': '',            # Name of data source provider
                                'src_link': '',            # link of data source provider
                                'src_key': '',             # key of data source provider
                                'confirmed': null_df,      # DataFrame for confirmed cases.
                                'deaths': null_df,         # DataFrame for deaths.
                                'recoveries': null_df},    # DataFrame for recoveries.
                        'usa': {'data_date': None,
                                'download_date': None,
                                'summary_cols': 0,
                                'header_cols': 0,
                                'src_name': '',
                                'src_link': '',
                                'src_key': '',
                                'confirmed': null_df,
                                'deaths': null_df,
                                'recoveries': null_df}}
        self.args = args                                   # Command line argument object.
        self.table_columns = args.columns

        # Initialize data with pickle file or reading from sources.
        if not self.read_datafile(download=download):
            print('Error: error while downloading sources.')
            sys.exit(-20)

    @classmethod
    def chk_args(cls, args):
        """
        Argument error checking used by this utility.
        :param args: args from args.parser
        :return: True if check passes else False
        :rtype: bool
        """
        if args.rwindow < 2:
            print('Error in value for --rwindow {}, must be an integer >= 2.'.format(args.rwindow))
            return False
        if args.mwindow < 1:
            print('Error in value for --mwindow {}, must be an integer >= 1.'.format(args.mwindow))
            return False
        if args.minimum < 0:
            print('Error in value for --minimum {}, must be an integer >= 0.'.format(args.minimum))
            return False
        if args.columns < 5:
            print('Error in value for --columns {}, must be an integer >= 5.'.format(args.columns))
            return False
        if args.threshold:
            if args.threshold <= 0:
                print('Error in value for --threshold {}, must be a positive integer.'.format(args.threshold))
                return False
        if args.response not in cls._valid_args['response']:
            print('Error in value for --response {}, valid values are {}'.format(args.response,
                                                                                 cls._valid_args['response']))
            return False
        if args.type not in cls._valid_args['type']:
            print('Error in value for --type {}, valid values are {}'.format(args.type,
                                                                             cls._valid_args['type']))
            return False
        if args.region not in cls._valid_args['region']:
            print('Error in value for --region {}, valid values are {}'.format(args.region,
                                                                               cls._valid_args['region']))
            return False
        if args.state not in ussa.us_state_abbrev.values():
            print('Error in value for --state {}, {} is not a valid US state abbreviation'.format(args.state,
                                                                                                  args.state))
            print('Valid state abbreviations: {}'.format(list(ussa.abbrev_us_state.keys())))
            return False
        if args.length <= 0:
            print('Error in value for --length {}, must be positive integer.'.format(args.length))
            return False
        if args.savedir:
            if re.search(r'[\\/?%*:|\"<>]', args.savedir):
                print('Error in value for --savedir {}, contains invalid characters'.format(args.savedir))
                return False
            if re.search(r'[\s]', args.savedir):
                print('Error in value for --savedir ',
                      '{}, there is a special place in heck for those who use spaces in directory names!'.format(
                          args.savedir))
                return False
        if args.exclude:
            if not re.fullmatch(r'([a-zA-Z]+(\s[a-zA-Z]+)*)+((,[a-zA-Z]+)+(\s[a-zA-Z]+)*)*', args.exclude):
                print('Invalid value for --exclude [{}], must be region names, separated by commas'.format(
                    args.exclude))
                return False
            args.exclude = args.exclude.lower().split(',')
        return True

    @classmethod
    def print_args(cls):
        """
        Prints valid arguments for command line options that require a string.
        :return: None
        """
        print('Valid argument values:')
        [print(' {}: {}'.format(k2, v2)) for k2, v2 in cls._valid_args.items()]

    @classmethod
    def print_sources(cls):
        """
        Formatted print of data sources used by this utility.
        :return: None
        """
        for k, v in cls._covid_data.items():
            print(k)
            [print(' {}: {}\n    {}'.format(k2, v2['src_name'], v2['url'])) for k2, v2 in v.items()]

    def read_datafile(self, download=False):
        """
        Read covid-19 data from the repository datafiles or a pickle file depends on value of download.
        :param download: Download from the interweb if True, else read pickled data.
        :type download: bool
        :return: True if successful
        :rtype: bool
        """
        # If a valid pickle file does not exist, download data even if download is False.
        if not download and os.path.isfile(self._pickle_filename):
            # Read pickle file.
            with open(self._pickle_filename, 'rb') as f:
                self.data = pickle.load(f)
            return True

        for zone, zone_dict in self._covid_data.items():
            for report_type, details in zone_dict.items():
                link = details['url']
                print(link)
                print('Downloading: Zone: {}, Type: {}'.format(zone, report_type))
                if self.args.debug:
                    temp_file_name = 'covid_{}_{}_{}.csv'.format(zone, report_type, 'test')
                else:
                    temp_file_name = 'covid_{}_{}_{}.csv'.format(zone, report_type,
                                                                 datetime.utcnow().strftime('%m%d_%H%M%S'))
                csv_data = None
                if not self.args.debug or not os.path.isfile(temp_file_name):
                    try:
                        csv_data = requests.get(link).content
                    except requests.exceptions.RequestException as err:
                        print('Error [{}]: could not download:\n   [{}].'.format(err, link))
                        continue
                read_df = pd.read_csv(io.StringIO(csv_data.decode('utf-8', errors='replace')), sep=',')
                # Delete unnamed columns
                read_df = read_df.loc[:, ~read_df.columns.str.contains('^Unnamed')]
                if zone == 'usa' and details['src_key'] == 'usf':
                    # Delete rows with null state or county name
                    read_df = read_df.loc[(~read_df['County Name'].isnull() | ~read_df['State'].isnull())].copy()
                if self.args.debug:
                    with pd.option_context('display.max_rows', None, 'show_dimensions', False):
                        print(read_df.head(1))
                self.data[zone][report_type] = self.read_csv_file(csv_data, zone, report_type, read_df)
                self.data[zone]['data_date'] = self.data[zone][report_type].columns[-(self.data[zone]['summary_cols']+1)]
                print('  Last data date: {}, Data size: {}'.format(self.data[zone]['data_date'], read_df.shape))
            self.data[zone]['download_date'] = datetime.utcnow()

        # Save pickle file.
        with open(self._pickle_filename, 'wb') as f:
            pickle.dump(self.data, f)

        return True

    def aggregate_world(self, df):
        """
        Aggregate global total from country level data.
        :param df: Target dataframe
        :type df: pandas.core.frame.DataFrame
        :return: Dataframe with aggregation row added
        :rtype: pandas.core.frame.DataFrame
        """
        head_cols = self.data['global']['header_cols']
        ac_df = df.loc[df['Province/State'].isnull()].copy()
        ac_df.iloc[:, head_cols:] = ac_df.iloc[:, head_cols:].fillna(0)
        world_df = ac_df.head(1).copy()
        world_df.iloc[:, head_cols:] = ac_df.values[:, head_cols:].sum(axis=0)
        world_df.loc[:, 'Country/Region'] = 'Global'
        world_df.loc[:, 'Province/State'] = np.NaN
        world_df.loc[:, 'Lat'] = 0.0
        world_df.loc[:, 'Long'] = 0.0
        fdf = pd.concat([df, world_df], ignore_index=True)
        return fdf

    def aggregate_state_prov(self, df, target_country):
        """
        Aggregate state/province level data to country totals.
        :param df: Target dataframe
        :type df: pandas.core.frame.DataFrame
        :param target_country: Country for aggregation
        :type target_country: str
        :return: dataframe with aggregation row added
        :rtype: pandas.core.frame.DataFrame
        """
        if target_country == 'US':
            head_cols = self.data['usa']['header_cols']
            fdf = df.copy()
            state_list = df['State'].unique()
            # TODO - Need to replace with pivot
            for state in state_list:
                sc_df = df.loc[df['State'] == state, :].copy()
                state_df = sc_df.head(1).copy()
                state_df.loc[0, head_cols:] = 0
                sc_df.iloc[:, head_cols:] = sc_df.iloc[:, head_cols:].fillna(0)
                state_df.loc[:, head_cols:] = sc_df.values[:, head_cols:].sum(axis=0)
                state_df = state_df.head(1).copy()
                state_df.loc[:, 'County'] = np.NaN
                fdf = pd.concat([fdf, state_df], ignore_index=True)
        else:
            head_cols = self.data['global']['header_cols']
            sp_df = df.loc[df['Country/Region'] == target_country, :].copy()
            sp_df.iloc[:, head_cols:] = sp_df.iloc[:, head_cols:].fillna(0)
            country_df = sp_df.head(1).copy()
            country_df.loc[:, head_cols:] = sp_df.values[:, head_cols:].sum(axis=0)
            country_df.loc[:, 'Province/State'] = np.NaN
            fdf = pd.concat([df, country_df], ignore_index=True)
        return fdf

    def read_csv_file(self, file_name, zone, report_type, df=None):
        """
        Read and pre-process the csv data files.  Format is from Johns Hopkins GitHub repo.
        :param file_name: File name of the csv file to be processed.
        :type file_name: str
        :param zone: global or usa file source.
        :type zone: str
        :param report_type: confirmed or deaths
        :type report_type: str
        :param df: dataframe to use instead of reading csv file.
        :type df: pandas.core.frame.DataFrame
        :return: Prepared dataframe
        :rtype df: pandas.core.frame.DataFrame
        """
        if df is None:
            try:
                df = pd.read_csv(file_name)
            except UnicodeDecodeError:
                df = pd.read_csv(file_name, encoding='ISO-8859-1')

        self.data[zone]['header_cols'] = self._covid_data[zone][report_type]['header_cols']
        self.data[zone]['summary_cols'] = self._covid_data[zone][report_type]['summary_cols']
        self.data[zone]['src_name'] = self._covid_data[zone][report_type]['src_name']
        self.data[zone]['src_link'] = self._covid_data[zone][report_type]['src_link']
        self.data[zone]['src_key'] = self._covid_data[zone][report_type]['src_key']
        if zone == 'global':
            for ps_country in self._prov_state_countries:
                df.loc[(df['Province/State'].isna()) & (df['Country/Region'] == ps_country),
                       'Province/State'] = ps_country
                df = self.aggregate_state_prov(df, ps_country)
            df = self.aggregate_world(df)
            df.loc[df['Country/Region'] == 'Taiwan*', 'Country/Region'] = 'Taiwan'
            df.loc[df['Country/Region'] == 'Korea, South', 'Country/Region'] = 'Korea'
        else:
            if self.data[zone]['src_key'] == 'usf':
                df = df.rename(columns={'County Name': 'County'})
            else:
                df = df.rename(columns={'Admin2': 'County'})
                df = df.rename(columns={'Province_State': 'State'})

                # Convert state names to abbreviations
                def get_state_abv(state_name):
                    """Get abbreviation for given state name"""
                    return ussa.us_state_abbrev[state_name] if state_name in ussa.us_state_abbrev.keys() else state_name
                df.loc[:, 'State'] = df.loc[:, 'State'].apply((lambda x: get_state_abv(x)))
            df = self.aggregate_state_prov(df, 'US')

        # Add Summary columns
        df.loc[:, 'Yesterday'] = df.iloc[:, -2]
        df.loc[:, 'Total'] = df.iloc[:, -2]
        df.loc[:, 'DayIncrease'] = df.loc[:, 'Total'] - df.loc[:, 'Yesterday']
        df.loc[:, '%DayIncrease'] = (df.loc[:, 'DayIncrease'] / df.loc[:, 'Yesterday'])
        df.loc[df['%DayIncrease'].isna(), '%DayIncrease'] = 0.0
        df.loc[:, '%DayIncrease'] = round(100.0 * df.loc[:, '%DayIncrease'], 1)
        self.data[zone]['summary_cols'] += 4
        num_cols = df.shape[1]
        col_select = np.r_[self.data[zone]['header_cols']:num_cols - self.data[zone]['summary_cols']]
        df.loc[:, 'DaysToDouble'] = df.iloc[:, col_select].apply(lambda x:
                                    cm.CovidMath.series_doubling_time(x.tolist()[-5:]), axis=1)
        self.data[zone]['summary_cols'] += 1
        return df

    def report_process(self, rdf):
        """
        Prepare selected dataset for generation of plot/table reports.
        :param rdf: target dataset
        :type rdf: pandas.core.frame.DataFrame
        :return: new processed dataframe
        :rtype: pandas.core.frame.DataFrame
        """
        # Pre-process data
        if self.args.threshold:
            rdf = rdf.loc[rdf['Total'] >= self.args.threshold]
        rdf.reset_index(drop=True, inplace=True)
        rdf = rdf.sort_values(['Total'], ascending=False).head(self.args.length)
        return rdf

    @staticmethod
    def get_col_select(df, name_list, summ_cols, head_cols, total_cols=10):
        """
        Get a numpy array that selects appropriate columns for table report.
        :param df:  Data frame for the table.
        :type df: pandas.core.frame.DataFrame
        :param name_list: List of column names.
        :type name_list: list
        :param summ_cols: Number of dataframe summary columns
        :type summ_cols: int
        :param head_cols: Number of dataframe header columns
        :type head_cols: int
        :param total_cols: Total number of columns for the table.
        :type total_cols: int
        :return: Object for column selection from dataframe
        :rtype: numpy.ndarray
        """
        x_cols = df.shape[1]
        h_index_list = []
        s_index_list = []
        # Skip all but specified Header columns
        for c_name in name_list:
            if c_name in df.columns:
                h_index_list.append(df.columns.get_loc(c_name))
        # Identify Summary columns, skipping Yesterday and Total
        for c_name in df.columns[x_cols - summ_cols:]:
            if c_name not in ['Yesterday', 'Total']:
                s_index_list.append(df.columns.get_loc(c_name))
        # Create a time series index list
        max_cols = x_cols - head_cols - summ_cols + len(s_index_list) + len(h_index_list)
        if total_cols > max_cols: total_cols = max_cols
        z = total_cols - len(s_index_list) - len(h_index_list) - 1
        ts_length = x_cols - summ_cols - head_cols
        ts_end_col = head_cols + ts_length

        return np.r_[h_index_list, head_cols, (ts_end_col - z):ts_end_col, s_index_list]

    def top_ten(self, plot=False):
        """
        Generate tabular data report.
        :param plot:  Flag to indicate if plot is requested.
        :type plot: bool
        :return: None
        """
        plot_file_name_suffix = 'png'
        table_file_name_suffix = 'txt'
        report_file_name = None
        table_df = plot_df = pd.DataFrame()
        zone = 'usa' if self.args.region != 'country' and self.args.country == 'US' else 'global'
        if self.args.region == 'country':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, self.args.region, zone, self.args.response)

            # Pre-process data
            temp_df = self.data[zone][self.args.type]
            tdf = temp_df.loc[temp_df['Province/State'].isnull()].copy()
            tdf = self.report_process(tdf)

            # Set the plot data
            if plot: plot_df = tdf.copy()

            # Select columns for table
            col_select = self.get_col_select(tdf, ['Country/Region'], self.data[zone]['summary_cols'],
                                             self.data[zone]['header_cols'], self.table_columns)
            table_df = tdf.iloc[:, col_select]

        elif self.args.region == 'state' or self.args.region == 'province':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, self.args.region,
                                                    self.args.country, self.args.response)

            if self.args.country == 'US':
                # Pre-process data
                temp_df = self.data[zone][self.args.type]
                tdf = temp_df.loc[temp_df['County'].isnull()].copy()
                tdf = self.report_process(tdf)

                # Set the plot data
                if plot: plot_df = tdf.copy()

                # Select columns for table
                col_select = self.get_col_select(tdf, ['State'], self.data[zone]['summary_cols'],
                                                 self.data[zone]['header_cols'], self.table_columns)
                table_df = tdf.iloc[:, col_select]

            else:
                # Pre-process data
                tdf = self.data['global'][self.args.type]
                tdf = tdf.loc[tdf['Country/Region'] == self.args.country].copy()
                tdf.loc[(tdf['Province/State'].isna()), 'Province/State'] = 'Total'
                tdf = self.report_process(tdf)

                # Set the plot data
                if plot: plot_df = tdf.copy()

                # Select columns for table
                col_select = self.get_col_select(tdf, ['Province/State', 'Country/Region'], self.data[zone]['summary_cols'],
                                                 self.data[zone]['header_cols'], self.table_columns)
                table_df = tdf.iloc[:, col_select].copy()

        elif self.args.region == 'county' or self.args.region == 'county-state':
            # Pre-process data
            temp_df = self.data[zone][self.args.type]
            if self.args.region == 'county':
                report_file_name = '{}_{}_{}_{}'.format(self.args.type, 'county',
                                                        self.args.state, self.args.response)
                tdf = temp_df.loc[temp_df['State'] == self.args.state].copy()
                tdf.loc[(tdf['County'].isna()), 'County'] = 'Total'
            else:
                report_file_name = '{}_{}_{}_{}'.format(self.args.type, 'county-state',
                                                        self.args.country, self.args.response)
                temp_df = self.data[zone][self.args.type]
                tdf = temp_df.loc[~temp_df['County'].isnull()].copy()
            tdf = self.report_process(tdf)

            # Set the plot data
            if plot: plot_df = tdf.copy()

            # Select columns for table
            col_select = self.get_col_select(tdf, ['County', 'State'], self.data[zone]['summary_cols'],
                                             self.data[zone]['header_cols'], self.table_columns)
            table_df = tdf.iloc[:, col_select].copy()

        else:
            print('Error: Invalid report specified.')
            sys.exit(-1)

        # Display and/or write report table.
        if self.args.showtable or self.args.savetable:
            file_ptr_list = [sys.stdout] if self.args.showtable else []
            table_file_name = '{}.{}'.format(report_file_name, table_file_name_suffix)
            if self.args.savedir:
                if not os.path.isdir(self.args.savedir):
                    os.mkdir(self.args.savedir, 0o775)
                table_file_name = os.path.join(self.args.savedir, table_file_name)
            if self.args.savetable: file_ptr_list.append(open(table_file_name, 'w'))
            for fp in file_ptr_list:
                # TODO - display age of data.
                name_1 = 'Confirmed' if self.args.type == 'confirmed' else 'Deaths'
                name_2 = 'Cases'
                markup = ('\x1B[3m', '\x1B[23m') if fp == sys.stdout else ('', '')
                print('', file=fp)
                print('Top {} {} Report - {}'.format(self.args.length, self.args.region, self.args.type), file=fp)
                print('  Top {} regions by {}, threshold = {} {} cases'.format(self.args.length, name_2,
                                                                               self.args.threshold, name_1), file=fp)
                print('  Extract downloaded: {} UTC'.format(self.data['global']['download_date']), file=fp)
                print('  Data last data point date: {}'.format(self.data['global']['data_date']), file=fp)
                with pd.option_context('display.max_rows', None, 'show_dimensions', False):
                    table_df.reset_index(drop=True, inplace=True)
                    print(table_df, file=fp)
                print('', file=fp)
                data_src = 'usa' if self.args.region != 'country' and self.args.country == 'US' else 'global'
                credit_str = 'Data from the {} extract at {}, Credit: {}'.format(
                             self.data[data_src]['data_date'],
                             self.data[data_src]['src_link'],
                             self.data[data_src]['src_name'])
                print('{}   {}\n   Analytics: {}{}'.format(markup[0], credit_str, self._analytics_source,
                                                           markup[1]), file=fp)
                print('', file=fp)
                if fp != sys.stdout:
                    fp.close()

        # Display and/or write plot.
        if plot:
            plot_file_name = '{}.{}'.format(report_file_name, plot_file_name_suffix)
            if self.args.savedir:
                if not os.path.isdir(self.args.savedir):
                    os.mkdir(self.args.savedir, 0o775)
                plot_file_name = os.path.join(self.args.savedir, plot_file_name)
            self.plot(plot_df, plot_file_name)

    def plot(self, pdf, plot_fname):
        """
        Plot the target dataframe to file or display.
        :param pdf: Target dataframe
        :type pdf: pandas.core.frame.DataFrame
        :param plot_fname: Plot filename used if saveplot is specified.
        :type plot_fname: str
        :return: None
        """
        # Basic report parameters
        actual_exclude_list = []
        data_src = 'usa' if self.args.region != 'country' and self.args.country == 'US' else 'global'
        plot_response = 'Total'
        num_cols = pdf.shape[1]
        col_select = np.r_[self.data[data_src]['header_cols']:num_cols-self.data[data_src]['summary_cols']]

        # Set credit string base on data source
        credit_str = 'Data from the {} extract at {}, Credit: {}'.format(
                     self.data[data_src]['data_date'],
                     self.data[data_src]['src_link'],
                     self.data[data_src]['src_name'])

        # Select label names based on report type and region
        if self.args.region == 'county-state':
            pdf.loc[:, 'County'] = pdf.loc[:, 'County'] + ', ' + pdf.loc[:, 'State']
        if self.args.region == 'country':
            plot_item_names = list(pdf['Country/Region'])
            trunc_len = 15
        else:
            if self.args.country == 'US':
                plot_item_names = list(pdf['State']) if self.args.region == 'state' else list(pdf['County'])
                trunc_len = 5 if self.args.region == 'state' else 25
            else:
                plot_item_names = list(pdf['Province/State'])
                trunc_len = 25

        # Prepare matplotlib figure.
        fig_size = 10
        fig = plt.figure(figsize=(fig_size, fig_size))
        ax = fig.add_subplot(1, 1, 1)
        ax.set_facecolor('#d0dbd5')
        fig.patch.set_facecolor('#eeeeee')
        plt.subplots_adjust(left=0.09, right=0.93, top=0.95)

        # Generate Plots
        max_days = max_cases = thresh = 0
        for pname in plot_item_names:
            # Skip regions in exclude list
            if pname.lower() in self.args.exclude:
                actual_exclude_list.append(pname)
                continue
            # Get time series values as y
            if self.args.region == 'country':
                y = pdf.loc[pdf['Country/Region'] == pname, :]
                total = pdf.loc[pdf['Country/Region'] == pname, plot_response].tolist()[0]
            else:
                if self.args.country == 'US':
                    y = pdf.loc[pdf['State'] == pname, :] if self.args.region == 'state' else \
                        pdf.loc[pdf['County'] == pname, :]
                    total = pdf.loc[pdf['State'] == pname, plot_response].tolist()[0] if self.args.region == 'state' \
                            else pdf.loc[pdf['County'] == pname, plot_response].tolist()[0]
                else:
                    y = pdf.loc[pdf['Province/State'] == pname, :]
                    total = pdf.loc[pdf['Province/State'] == pname, plot_response].tolist()[0]
            y = list(y.iloc[0, col_select])

            # Construct legend name with values
            if isinstance(total, (int, np.int64)):
                lname = '{} ({})'.format(pname[:trunc_len], total)
            else:
                lname = '{} ({})'.format(pname[:trunc_len], round(total, 1))
            if self.args.debug: print('{} {}\ny = {}..{}'.format(lname, len(y), y[0:4], y[-4:]))

            # Plot lines and label
            if self.args.response == 'new-total':
                x, y = self.plot_prep_new_total(y, self.args.mwindow)
                if not x or not y: continue
                if self.args.debug:
                    print('{}\nx = {}..{}\ny = {}..{}'.format(lname, x[0:4], x[-4:], y[0:4], y[-4:]))
                    print(pdf)
                ax.set_yscale('log')
                ax.set_xscale('log')
                ax.plot(x, y, label=lname)
                ax.text(x=x[-1], y=y[-1], s=pname,
                        bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)
            elif self.args.response == 'rdtd':
                if self.args.threshold:
                    thresh = self.args.threshold
                else:
                    thresh = 5 if self.args.type == 'deaths' else 100

                # Skip Global and Diamond Princess
                if pname == 'Diamond Princess' or pname == 'Global':
                    actual_exclude_list.append(pname)
                    continue

                # Set starting point of each series an create rdtd series
                y = cm.CovidMath.start_at_threshold(y, thresh)
                if len(y) <= self.args.minimum: continue
                y = cm.CovidMath.series_rolling_doubling_time(y, self.args.rwindow)
                if self.args.debug:
                    print('{} {}\ny = {}..{}'.format(lname, len(y), y[0:4], y[-4:]))
                    print(pdf)

                # Plot the lines
                ax.set_yscale('log')
                tname = '{} ({})'.format(pname, y[-1])
                ax.plot(y, label=lname)
                ax.text(x=len(y)-1, y=y[-1], s=tname,
                        bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)
            elif self.args.response == 'trajectory':
                if self.args.threshold:
                    thresh = self.args.threshold
                else:
                    thresh = 5 if self.args.type == 'deaths' else 100
                # Skip Global and Diamond Princess
                if pname == 'Diamond Princess' or pname == 'Global':
                    actual_exclude_list.append(pname)
                    continue

                # Set starting point of each series, get last element rdtd value, and smooth y
                y = cm.CovidMath.start_at_threshold(y, thresh)
                if len(y) < self.args.minimum: continue
                if self.args.debug:
                    print('{} {}\ny = {}..{}'.format(lname, len(y), y[0:4], y[-4:]))
                    print(pdf)
                rdtd_val = cm.CovidMath.series_doubling_time(y[-5:])
                y = cm.CovidMath.moving_average(y, self.args.mwindow)

                # Max values are used later to plot reference lines
                max_days = len(y) if len(y) > max_days else max_days
                max_cases = max(y) if max(y) > max_cases else max_cases

                # Plot the lines
                ax.set_yscale('log')
                ax.plot(y, label=lname)
                ax.text(x=len(y)-1, y=y[-1], s='{} ({})'.format(pname, rdtd_val),
                        bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)
            else:
                if self.args.debug:
                    print('{} {}\ny = {}..{}'.format(lname, len(y), y[0:4], y[-4:]))
                    print(pdf)
                ax.set_yscale('log')
                ax.plot(y, label=lname)
                ax.text(x=len(y)-1, y=y[-1], s=pname,
                        bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)

        # Finish plots
        name_0 = 'Rolling Days to Double' if self.args.response == 'rdtd' else ''
        name_1 = 'Confirmed' if self.args.type == 'confirmed' else 'Deaths'
        name_2 = 'Cases'
        data_desc = 'Top {} regions by {}, threshold = {} {} cases'.format(self.args.length, name_2,
                                                                           self.args.threshold, name_1)
        if self.args.response == 'trajectory':
            # Plot reference rate lines
            for d2d in [1, 2, 4, 7, 14]:
                ref_y = [thresh]
                for i in range(1, d2d*20):
                    ref_y.append(ref_y[0]*(2**(1/d2d))**i)
                lname = pname = '2x/{}Day'.format(d2d)
                ref_y = cm.CovidMath.truncate_series(ref_y, max_days, max_cases)
                ax.plot(ref_y, label=lname, color='#444444', linestyle=':', linewidth=2)
                with plt.style.context({'text.color': '#ffffff'}):
                    ax.text(x=len(ref_y)-1, y=ref_y[-1], s=pname,
                            bbox=dict(boxstyle='round,pad=0.2', facecolor='#444444'), fontsize=6)
            data_desc = '{}, Rolling win size: {}, Moving Avg win size: {}'.format(data_desc,
                                                                                   self.args.rwindow,
                                                                                   self.args.mwindow)
            plt.ylabel('{} {}'.format(name_1, name_2), fontsize=16)
            plt.xlabel('Days Since {} {}'.format(thresh, name_1), fontsize=16)
            ax.grid(True)
        elif self.args.response == 'rdtd':
            data_desc = '{}, Rolling win size: {}'.format(data_desc, self.args.rwindow)
            plt.ylabel('Days to Double {}'.format(name_1), fontsize=16)
            plt.xlabel('Days Since {} {}'.format(thresh, name_1), fontsize=16)
            ax.grid(b=True, which='major', color='#888888')
            ax.grid(b=True, which='minor', color='#CCCCCC')
            plt.tick_params(axis='y', which='minor')
            ax.yaxis.set_minor_formatter(FormatStrFormatter("%d"))
            for tick in ax.yaxis.get_minor_ticks():
                tick.label.set_fontsize(6)
            ax.legend(loc="upper left", fontsize=8)
        elif self.args.response == 'new-total':
            data_desc = '{}, Moving Avg win size: {}'.format(data_desc, self.args.mwindow)
            plt.ylabel('New {}'.format(name_1), fontsize=16)
            plt.xlabel('Total {}'.format(name_1), fontsize=16)
            ax.grid(True)
            #plt.tick_params(axis='y', which='minor')
            #ax.yaxis.set_minor_formatter(FormatStrFormatter("%d"))
            #for tick in ax.yaxis.get_minor_ticks():
                #tick.label.set_fontsize(5)
            ax.legend(loc="upper left", fontsize=8)
        else:
            plt.ylabel('{} {}'.format(name_1, name_2), fontsize=16)
            plt.xlabel('Days Since Outbreak', fontsize=16)
            ax.grid(True)
            ax.legend(loc="upper left", fontsize=8)

        # Now add details to the plot
        if self.args.region == 'country':
            name_region = 'Country'
        elif self.args.region == 'state' or self.args.region == 'province':
            ps = 'State' if self.args.country == 'US' else 'Province/State'
            name_region = '{} for {}'.format(ps, self.args.country)
        elif self.args.region == 'county-state':
            name_region = '{} {}'.format('US', 'County, State')
        else:
            state_name = ussa.abbrev_us_state[self.args.state]
            name_region = 'County for {}'.format(state_name)

        # Plot parameters
        x_tick_adjust = 0.11
        exclude_str = 'Excluded regions: {}\n'.format(actual_exclude_list) if actual_exclude_list else ''
        plt.figtext(0.99, 0.01, '{}{}\n{}\nAnalytics: {}'.format(exclude_str, data_desc, credit_str,
                    self._analytics_source), horizontalalignment='right', fontsize=8)
        fig.subplots_adjust(bottom=x_tick_adjust)
        title_fs = 17 if self.args.response == 'rdtd' else 19
        ax.set_title('COVID-19 {} {} {} by {}'.format(name_0, name_1, name_2, name_region),
                     fontsize=title_fs, fontweight='bold')

        # Output plot
        if self.args.saveplot:
            plt.savefig(plot_fname, quality=90, optimize=True)
        if self.args.showplot:
            plt.show()

    def plot_prep_new_total(self, y_list, lookback):
        """
        Prepare data for the new-total plot.
        :param y_list:
        :type y_list: list
        :param lookback: The size of the moving average window.
        :type lookback: int
        :return: tuple of x and y lists
        :rtype: tuple
        """
        if self.args.threshold:
            thresh = self.args.threshold
        else:
            thresh = 5 if self.args.type == 'deaths' else 100

        # Copy incoming list to y (new) and x (total
        x = y_list[:]
        y = y_list[:]

        # Get index for threshold
        start_index = cm.CovidMath.threshold_index(y_list, thresh)

        # Create y as incremental cases per day
        y = cm.CovidMath.total_to_increment(x)
        y = cm.CovidMath.moving_average(y, lookback)
        return x[start_index:], y[start_index:]


def main():
    """
    Main flow for covid19-vi.
    :return: None
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('--about', help='display information about this utility',
                        action='store_true', default=False)
    parser.add_argument('--minimum', help='where applicable, excludes regions where times series shorter than minimum',
                        type=int, default=1)
    parser.add_argument('--columns', help='number of columns in table report',
                        type=int, default=10)
    parser.add_argument('--length', help='data length for sorted reports',
                        type=int, default=10)
    parser.add_argument('--threshold', help='threshold of case number to be included',
                        type=int, default=None)
    parser.add_argument('--mwindow', help='size of the window for moving avg',
                        type=int, default=3)
    parser.add_argument('--rwindow', help='size of the window for rolling days to double',
                        type=int, default=10)
    parser.add_argument('--country', help='name of country for state/province reports',
                        type=str, default='US')
    parser.add_argument('--state', help='name of state for county reports',
                        type=str, default='NY')
    parser.add_argument('--region', help='scope of report: country, state, province, county, county-state',
                        type=str, default='country')
    parser.add_argument('--type', help='type of report: confirmed, deaths',
                        type=str, default='confirmed')
    parser.add_argument('--exclude', help='comma separated list of regions to exclude',
                        type=str, default='')
    parser.add_argument('--response', help='response: log, linear, new-total, trajectory, rdtd',
                        type=str, default='log')
    parser.add_argument('--sources', help='list sources used by this utility',
                        action='store_true', default=False)
    parser.add_argument('--download', help='download data from sources and save to local pickle',
                        action='store_true', default=False)
    parser.add_argument('--saveplot', help='save plot to a file',
                        action='store_true', default=False)
    parser.add_argument('--showplot', help='display plot',
                        action='store_true', default=False)
    parser.add_argument('--savetable', help='save table to a file',
                        action='store_true', default=False)
    parser.add_argument('--showtable', help='display table',
                        action='store_true', default=False)
    parser.add_argument('--savedir', help='destination for saving files',
                        type=str, default=None)
    parser.add_argument('--debug', help='debug output',
                        action='store_true', default=False)
    args = parser.parse_args()

    # About me
    if args.about:
        print(__doc__)
        print('Author: ', __author__)
        print('Copyright: ', __copyright__)
        print('Credits: ', __credits__)
        print('License: ', __license__)
        print('Version: ', __version__)
        print('Maintainer: ', __maintainer__)
        print('Status: ', __status__)
        print('')
        CovidData.print_args()
        print('')
        sys.exit(0)

    if not CovidData.chk_args(args):
        print('Error: invalid arguments.')
        sys.exit(-10)

    if args.sources:
        CovidData.print_sources()

    plot = True if args.showplot or args.saveplot else False
    table = True if args.showtable or args.savetable else False

    covid_data = CovidData(args=args, download=args.download)

    if table or plot:
        covid_data.top_ten(plot=plot)

    sys.exit(0)


if __name__ == '__main__':
    main()
