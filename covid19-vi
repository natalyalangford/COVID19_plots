#!/usr/bin/env python3
""" covid19-vi  -  Visualization utilities for the COVID-19 data from Johns Hopkins.

    The *covid19-vi* utility is the main interface for the projects access to the public COVID-19
    time series data.  The *--download* option is used to retrieve the latest data from the
    sources defined in the project. The data is read with a url request and loaded into a
    dataframe.  The dataframe is processed with error checkers, aggretators, and analytics
    utilities and then pickled for quicker use by the utility.

    Copyright (C) 2020  Natalya Langford

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""
__author__ = 'Natalya Langford'
__copyright__ = 'Copyright (C) 2020 Natalya Langford'
__credits__ = ['Ricks-Lab - Collaborator']
__license__ = 'GNU General Public License'
__program_name__ = 'covid19-vi'
__version__ = 'v0.0.1'
__maintainer__ = 'Natalya Langford'
__status__ = 'Under Development'
__docformat__ = 'reStructuredText'
# pylint: disable=multiple-statements
# pylint: disable=line-too-long

import argparse
import sys
import re
import os
from datetime import datetime
import io
import pickle
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import us_state_abbrev as ussa


class CovidData:
    """
    Class for downloading, processing, and reporting on COVID-19 time series data.
    """
    _covid_data = {'global': {'confirmed': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',
                              'deaths': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'},
                   'usa': {'confirmed': 'https://static.usafacts.org/public/data/covid-19/covid_confirmed_usafacts.csv',
                           'deaths': 'https://static.usafacts.org/public/data/covid-19/covid_deaths_usafacts.csv'}}
    _pickle_filename = 'covid_data.pickle'
    _prov_state_countries = ['China', 'Canada', 'Australia', 'France', 'United Kingdom', 'Netherlands', 'Denmark']
    _data_source = {'global': {'link': 'https://github.com/CSSEGISandData/COVID-19',
                               'name': 'Johns Hopkins University'},
                    'usa': {'link': 'https://usafacts.org/issues/coronavirus/',
                            'name': 'USA Facts'}}
    _analytics_source = 'https://github.com/natalyalangford/COVID19_plots'
    _valid_args = {'type': ['deaths', 'confirmed'],
                   'region': ['country', 'state', 'province', 'county', 'county-state'],
                   'response': ['log', 'linear', 'growth', 'new-total']}

    def __init__(self, args, download=False):
        """
        Initialize a CovidData object and populate from interweb if download is True.
        :param download: Flag to force actual download instead of using pickled data.
        :type download: Bool
        :return None
        """
        self.data = {'global': {'data_date': None,
                                'download_date': None,
                                'confirmed': None,
                                'deaths': None,
                                'recoveries': None},
                     'usa': {'data_date': None,
                             'download_date': None,
                             'confirmed': None,
                             'deaths': None,
                             'recoveries': None}}
        self.args = args
        if not self.read_datafile(download=download):
            print('Error: error while downloading sources.')
            sys.exit(-20)

    @classmethod
    def chk_args(cls):
        """
        Argument error checking used by this utility.
        :return: True if check passes else False
        :rtype: bool
        """
        if cls.args.threshold:
            if cls.args.threshold <= 0:
                print('Error in value for --threshold {}, must be a positive integer.'.format(cls.args.threshold))
                return False
        if cls.args.response not in cls._valid_args['response']:
            print('Error in value for --response {}, valid values are {}'.format(cls.args.response,
                                                                                 cls._valid_args['response']))
            return False
        if cls.args.type not in cls._valid_args['type']:
            print('Error in value for --type {}, valid values are {}'.format(cls.args.type,
                                                                             cls._valid_args['type']))
            return False
        if cls.args.region not in cls._valid_args['region']:
            print('Error in value for --region {}, valid values are {}'.format(cls.args.region,
                                                                               cls._valid_args['region']))
            return False
        if cls.args.state not in ussa.us_state_abbrev.values():
            print('Error in value for --state {}, {} is not a valid US state abbreviation'.format(cls.args.state,
                                                                                                  cls.args.state))
            print('Valid state abbreviations: {}'.format(list(ussa.abbrev_us_state.keys())))
            return False
        if cls.args.length <= 0:
            print('Error in value for --length {}, must be positive integer.'.format(cls.args.length))
            return False
        if cls.args.savedir:
            if re.search(r'[\\/?%*:|\"<>]', cls.args.savedir):
                print('Error in value for --savedir {}, contains invalid characters'.format(cls.args.savedir))
                return False
            if re.search(r'[\s]', cls.args.savedir):
                print('Error in value for --savedir ',
                      '{}, there is a special place in hell for people who use spaces in directory names.'.format(
                          cls.args.savedir))
                return False
        return True

    @classmethod
    def print_args(cls):
        """
        Prints valid arguments for command line options that require a string.
        :return:
        """
        print('Valid argument values:')
        [print(' {}: {}'.format(k2, v2)) for k2, v2 in cls._valid_args.items()]

    def print_sources(self):
        """
        Formatted print of data sources used by this utility.
        :return: None
        """
        for k, v in self._covid_data.items():
            print(k)
            [print(' {}: {}'.format(k2, v2)) for k2, v2 in v.items()]

    def read_datafile(self, download=False):
        """
        Read covid-19 data from the repository datafiles or a pickle file depends on value of download.
        Source: https://github.com/Ricks-Lab/amdgpu-utils/blob/c10dba61f11b9e5fb44d24acd1fa74122668afc2/GPUmodules/PCImodule.py

        :param download: Download from the interweb if True, else read pickled data.
        :type download: bool
        :return: bool
        """
        if not download and os.path.isfile(self._pickle_filename):
            # Read pickle file.
            with open(self._pickle_filename, 'rb') as f:
                self.data = pickle.load(f)
            return True

        for zone, zone_dict in self._covid_data.items():
            #if zone == 'global': continue
            for report_type, link in zone_dict.items():
                print('Downloading: Zone: {}, Type: {}'.format(zone, report_type))
                if self.args.debug:
                    temp_file_name = 'covid_{}_{}_{}.csv'.format(zone, report_type, 'test')
                else:
                    temp_file_name = 'covid_{}_{}_{}.csv'.format(zone, report_type,
                                                                 datetime.utcnow().strftime('%m%d_%H%M%S'))
                if not self.args.debug or not os.path.isfile(temp_file_name):
                    try:
                        csv_data = requests.get(link).content
                    except requests.exceptions.RequestException as err:
                        print('Error [{}]: could not download:\n   [{}].'.format(err, link))
                        continue
                read_df = pd.read_csv(io.StringIO(csv_data.decode('utf-8', errors='replace')), sep=',')
                # Delete unnamed columns
                read_df = read_df.loc[:, ~read_df.columns.str.contains('^Unnamed')]
                if zone == 'usa':
                    # Delete rows with null state or county name
                    read_df = read_df.loc[(~read_df['County Name'].isnull() | ~read_df['State'].isnull())].copy()
                if self.args.debug:
                    with pd.option_context('display.max_rows', None, 'show_dimensions', False):
                        print(read_df.head(1))
                self.data[zone][report_type] = self.read_csv_file(csv_data, zone, read_df)
                self.data[zone]['data_date'] = self.data[zone][report_type].columns[-5]
                print('  Last data date: {}, Data size: {}'.format(self.data[zone]['data_date'], read_df.shape))
            self.data[zone]['download_date'] = datetime.utcnow()

        # Save pickle file.
        with open(self._pickle_filename, 'wb') as f:
            pickle.dump(self.data, f)

        return True

    @staticmethod
    def aggregate_world(df):
        """
        Aggregate global total from country level data.
        :param df: Target dataframe
        :type df: pandas.core.frame.DataFrame
        :return: Dataframe with aggregation row added
        :rtype: pandas.core.frame.DataFrame
        """
        ac_df = df.loc[df['Province/State'].isnull()].copy()
        ac_df.iloc[:, 5:] = ac_df.iloc[:, 5:].fillna(0)
        world_df = ac_df.head(1).copy()
        world_df.iloc[:, 5:] = ac_df.values[:, 5:].sum(axis=0)
        world_df.loc[:, 'Country/Region'] = 'Global'
        world_df.loc[:, 'Province/State'] = np.NaN
        world_df.loc[:, 'Lat'] = 0.0
        world_df.loc[:, 'Long'] = 0.0
        fdf = pd.concat([df, world_df], ignore_index=True)
        return fdf

    @staticmethod
    def aggregate_state_prov(df, target_country):
        """
        Aggregate state/province level data to country totals.
        :param df: Target dataframe
        :type df: pandas.core.frame.DataFrame
        :param target_country: Country for aggregation
        :type target_country: str
        :return: dataframe with aggregation row added
        :rtype: pandas.core.frame.DataFrame
        """
        if target_country == 'US':
            fdf = df.copy()
            state_list = df['State'].unique()
            # TODO - Need to replace with pivot
            for state in state_list:
                sc_df = df.loc[df['State'] == state, :].copy()
                state_df = sc_df.head(1).copy()
                state_df.loc[0, 4:] = 0
                sc_df.iloc[:, 4:] = sc_df.iloc[:, 4:].fillna(0)
                state_df.loc[:, 4:] = sc_df.values[:, 4:].sum(axis=0)
                state_df = state_df.head(1).copy()
                state_df.loc[:, 'County Name'] = np.NaN
                fdf = pd.concat([fdf, state_df], ignore_index=True)
        else:
            sp_df = df.loc[df['Country/Region'] == target_country, :].copy()
            sp_df.iloc[:, 5:] = sp_df.iloc[:, 5:].fillna(0)
            country_df = sp_df.head(1).copy()
            country_df.loc[:, 5:] = sp_df.values[:, 5:].sum(axis=0)
            country_df.loc[:, 'Province/State'] = np.NaN
            fdf = pd.concat([df, country_df], ignore_index=True)
        return fdf

    def read_csv_file(self, file_name, zone, df=None):
        """
        Read and pre-process the csv data files.  Format is from Johns Hopkins GitHub repo.
        :param file_name: File name of the csv file to be processed.
        :type file_name: str
        :param zone: global or usa file source.
        :type zone: str
        :param df: dataframe to use instead of reading csv file.
        :type df: pandas.core.frame.DataFrame
        :return: list
        """
        if df is None:
            try:
                df = pd.read_csv(file_name)
            except UnicodeDecodeError:
                df = pd.read_csv(file_name, encoding='ISO-8859-1')

        if zone == 'global':
            for ps_country in self._prov_state_countries:
                df.loc[(df['Province/State'].isna()) & (df['Country/Region'] == ps_country),
                       'Province/State'] = ps_country
                df = self.aggregate_state_prov(df, ps_country)
            df = self.aggregate_world(df)
            df.loc[df['Country/Region'] == 'Taiwan*', 'Country/Region'] = 'Taiwan'
        else:
            df = self.aggregate_state_prov(df, 'US')
        # TODO - add days to double metric
        df.loc[:, 'Yesterday'] = df.iloc[:, -2]
        df.loc[:, 'Total'] = df.iloc[:, -2]
        df.loc[:, 'DayIncrease'] = df.loc[:, 'Total'] - df.loc[:, 'Yesterday']
        df.loc[:, '%DayIncrease'] = (df.loc[:, 'DayIncrease'] / df.loc[:, 'Yesterday'])
        df.loc[df['%DayIncrease'].isna(), '%DayIncrease'] = 0.0
        df.loc[:, '%DayIncrease'] = round(100.0 * df.loc[:, '%DayIncrease'], 1)
        return df

    @staticmethod
    def day_percent_growth(df, file_zone):
        """
        Calculate daily percentage growth based on past growth numbers, and populate Median with 3 day median.
        :param df: target dataset
        :type df: pandas.core.frame.DataFrame
        :param file_zone: Zone for data: usa or global
        :type file_zone: str
        :return: New dataframe with cases replaced by growth percentage
        :rtype: pandas.core.frame.DataFrame
        """
        # TODO - Need regression fit to calculate rate of increase instead of 3 day median
        dpd_df = df.copy(deep=True)
        series_start = 4 if file_zone == 'usa' else 5
        series_end = df.shape[1] - 4
        dpd_df.iloc[:, series_start:series_end] = \
            (df.iloc[:, series_start:series_end].pct_change(axis=1) * 100.0).round(1)
        with pd.option_context('mode.use_inf_as_na', True):
            dpd_df.iloc[:, series_start:series_end] = dpd_df.iloc[:, series_start:series_end].fillna(0.0)
        dpd_df.loc[:, 'Cases'] = dpd_df.loc[:, 'Total']
        dpd_df.loc[:, 'Total'] = dpd_df.iloc[:, series_end-3:series_end].median(axis=1, skipna=True, numeric_only=True)
        dpd_df = dpd_df.rename(columns={'Total': 'Median'})
        dpd_df = dpd_df.drop('%DayIncrease', axis=1)
        dpd_df = dpd_df.drop('Yesterday', axis=1)
        dpd_df.reset_index(drop=True, inplace=True)
        dpd_df.loc[:, 'DayIncrease'] = dpd_df.iloc[:, -4] - dpd_df.iloc[:, -5]
        return dpd_df

    def report_process(self, rdf, glb_usa):
        """
        Prepare selected dataset for generation of plot/table reports.
        :param rdf: target dataset
        :type rdf: pandas.core.frame.DataFrame
        :param glb_usa: process as global or usa dataset
        :type glb_usa: str
        :return: new processed dataframe
        :rtype: pandas.core.frame.DataFrame
        """
        # Pre-process data
        #rdf = rdf.loc[rdf['Total'] >= self.args.threshold] if self.args.threshold else \
            #rdf.sort_values(['Total'], ascending=False).head(self.args.length)
        if self.args.threshold:
            rdf = rdf.loc[rdf['Total'] >= self.args.threshold]
        rdf.reset_index(drop=True, inplace=True)

        # Process for growth or number
        if self.args.response == 'growth':
            rdf.reset_index(drop=True, inplace=True)
            rdf = self.day_percent_growth(rdf, glb_usa)
            # rdf = rdf.sort_values(['Median'], ascending=False)
            rdf = rdf.sort_values(['Median'], ascending=False).head(self.args.length)
        else:
            rdf = rdf.sort_values(['Total'], ascending=False).head(self.args.length)
        return rdf

    def top_ten(self, plot=False):
        """
        Generate tabular data report.
        :param plot:  Flag to indicate if plot is requested.
        :type plot: bool
        :return: None
        """
        plot_file_name_suffix = 'png'
        table_file_name_suffix = 'txt'
        report_file_name = None
        table_df = plot_df = pd.DataFrame()
        if self.args.region == 'country':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, self.args.region, 'global', self.args.response)

            # Pre-process data
            temp_df = self.data['global'][self.args.type]
            tdf = temp_df.loc[temp_df['Province/State'].isnull()].copy()
            tdf = tdf.drop('Province/State', axis=1)
            tdf = self.report_process(tdf, 'global')

            # Set the plot data
            if plot:
                plot_df = tdf.copy()

            # Select columns for table
            num_cols = tdf.shape[1]
            col_select = np.r_[0:1, num_cols-11:num_cols]
            table_df = tdf.iloc[:, col_select]

        elif self.args.region == 'state' or self.args.region == 'province':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, self.args.region,
                                                    self.args.country, self.args.response)

            if self.args.country == 'US':
                # Pre-process data
                temp_df = self.data['usa'][self.args.type]
                tdf = temp_df.loc[temp_df['County Name'].isnull()].copy()
                tdf = self.report_process(tdf, 'usa')

                # Set the plot data
                if plot:
                    plot_df = tdf.copy()

                # Select columns for table
                num_cols = tdf.shape[1]
                col_select = np.r_[2, num_cols-10:num_cols]
                table_df = tdf.iloc[:, col_select]

            else:
                # Pre-process data
                tdf = self.data['global'][self.args.type]
                tdf = tdf.loc[tdf['Country/Region'] == self.args.country].copy()
                tdf.loc[(tdf['Province/State'].isna()), 'Province/State'] = 'Total'
                tdf = self.report_process(tdf, 'global')

                # Set the plot data
                if plot:
                    plot_df = tdf.copy()

                num_cols = tdf.shape[1]
                col_select = np.r_[0:2, num_cols-8:num_cols]
                table_df = tdf.iloc[:, col_select].copy()

        elif self.args.region == 'county':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, 'county', self.args.state, self.args.response)

            # Pre-process data
            temp_df = self.data['usa'][self.args.type]
            tdf = temp_df.loc[temp_df['State'] == self.args.state].copy()
            tdf.loc[(tdf['County Name'].isna()), 'County Name'] = 'Total'
            tdf = self.report_process(tdf, 'usa')

            # Set the plot data
            if plot:
                plot_df = tdf.copy()

            num_cols = tdf.shape[1]
            col_select = np.r_[1:3, num_cols-8:num_cols]
            table_df = tdf.iloc[:, col_select].copy()

        elif self.args.region == 'county-state':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, 'county-state',
                                                    self.args.country, self.args.response)

            # Pre-process data
            temp_df = self.data['usa'][self.args.type]
            tdf = temp_df.loc[~temp_df['County Name'].isnull()].copy()
            tdf = self.report_process(tdf, 'usa')

            # Set the plot data
            if plot:
                plot_df = tdf.copy()

            num_cols = tdf.shape[1]
            col_select = np.r_[1:3, num_cols - 8:num_cols]
            table_df = tdf.iloc[:, col_select].copy()

        else:
            print('Error: Invalid report specified.')
            sys.exit(-1)

        # Display and/or write report table.
        if self.args.showtable or self.args.savetable:
            file_ptr_list = [sys.stdout] if self.args.showtable else []
            table_file_name = '{}.{}'.format(report_file_name, table_file_name_suffix)
            if self.args.savedir:
                if not os.path.isdir(self.args.savedir):
                    os.mkdir(self.args.savedir, 0o775)
                table_file_name = os.path.join(self.args.savedir, table_file_name)
            if self.args.savetable: file_ptr_list.append(open(table_file_name, 'w'))
            for fp in file_ptr_list:
                # TODO - display age of data.
                name_1 = 'Confirmed' if self.args.type == 'confirmed' else 'Deaths'
                name_2 = 'Growth' if self.args.response == 'growth' else 'Cases'
                markup = ('\x1B[3m', '\x1B[23m') if fp == sys.stdout else ('', '')
                print('', file=fp)
                print('Top {} {} Report - {}'.format(self.args.length, self.args.region, self.args.type), file=fp)
                print('  Top {} {} for regions, threshold = {} {} cases'.format(self.args.length, name_2,
                                                                                self.args.threshold, name_1), file=fp)
                print('  Extract downloaded: {} UTC'.format(self.data['global']['download_date']), file=fp)
                print('  Data last data point date: {}'.format(self.data['global']['data_date']), file=fp)
                with pd.option_context('display.max_rows', None, 'show_dimensions', False):
                    table_df.reset_index(drop=True, inplace=True)
                    print(table_df, file=fp)
                print('', file=fp)
                data_src = 'usa' if self.args.region != 'country' and self.args.country == 'US' else 'global'
                credit_str = 'Data from the {} extract at {}, Credit: {}'.format(
                             self.data[data_src]['data_date'],
                             self._data_source[data_src]['link'],
                             self._data_source[data_src]['name'])
                print('{}   {}\n   Analytics: {}{}'.format(markup[0], credit_str, self._analytics_source,
                                                           markup[1]), file=fp)
                print('', file=fp)
                if fp != sys.stdout:
                    fp.close()

        # Display and/or write plot.
        if plot:
            plot_file_name = '{}.{}'.format(report_file_name, plot_file_name_suffix)
            if self.args.savedir:
                if not os.path.isdir(self.args.savedir):
                    os.mkdir(self.args.savedir, 0o775)
                plot_file_name = os.path.join(self.args.savedir, plot_file_name)
            self.plot(plot_df, plot_file_name)

    def plot(self, pdf, plot_fname):
        """
        Plot the target dataframe to file or display.
        :param pdf: Target dataframe
        :type pdf: pandas.core.frame.DataFrame
        :param plot_fname: Plot filename used if saveplot is specified.
        :type plot_fname: str
        :return: None
        """
        # Basic report parameters
        plot_response = 'Median' if self.args.response == 'growth' else 'Total'
        num_cols = pdf.shape[1]
        col_select = np.r_[4:num_cols-4]

        # Set credit string base on data source
        data_src = 'usa' if self.args.region != 'country' and self.args.country == 'US' else 'global'
        credit_str = 'Data from the {} extract at {}, Credit: {}'.format(
                     self.data[data_src]['data_date'],
                     self._data_source[data_src]['link'],
                     self._data_source[data_src]['name'])

        # Select label names based on report type and region
        if self.args.region == 'county-state':
            pdf.loc[:, 'County Name'] = pdf.loc[:, 'County Name'] + ', ' + pdf.loc[:, 'State']
            trunc_len = 25
        if self.args.region == 'country':
            col_select = np.r_[3:num_cols - 4]
            plot_item_names = list(pdf['Country/Region'])
            trunc_len = 15
        else:
            if self.args.country == 'US':
                plot_item_names = list(pdf['State']) if self.args.region == 'state' else list(pdf['County Name'])
                trunc_len = 5 if self.args.region == 'state' else 25
            else:
                plot_item_names = list(pdf['Province/State'])
                trunc_len = 25

        # Prepare matplotlib figure.
        fig = plt.figure(figsize=(10, 10))
        ax = fig.add_subplot(1, 1, 1)
        if self.args.response == 'log' or self.args.response == 'new-total':
            ax.set_yscale('log')
            if self.args.response == 'new-total':
                ax.set_xscale('log')
        ax.set_facecolor('#d0dbd5')
        fig.patch.set_facecolor('#eeeeee')

        # Generate Plots
        bar_y = []
        bar_l = []
        for pname in plot_item_names:
            # Get parameter values as y
            if self.args.region == 'country':
                y = pdf.loc[pdf['Country/Region'] == pname, :]
                total = pdf.loc[pdf['Country/Region'] == pname, plot_response].tolist()[0]
                bar_y.append(total)
            else:
                if self.args.country == 'US':
                    y = pdf.loc[pdf['State'] == pname, :] if self.args.region == 'state' else \
                        pdf.loc[pdf['County Name'] == pname, :]
                    total = pdf.loc[pdf['State'] == pname, plot_response].tolist()[0] if self.args.region == 'state' \
                            else pdf.loc[pdf['County Name'] == pname, plot_response].tolist()[0]
                    bar_y.append(total)
                else:
                    y = pdf.loc[pdf['Province/State'] == pname, :]
                    total = pdf.loc[pdf['Province/State'] == pname, plot_response].tolist()[0]
                    bar_y.append(total)
            y = list(y.iloc[0, col_select])

            # Construct legend name with values
            lname = '{} ({})'.format(pname[:trunc_len], total)

            # Plot lines and label or collect bar plot details for later
            if self.args.response == 'growth':
                bar_l.append('{}'.format(lname))
            else:
                if self.args.response == 'new-total':
                    if self.args.threshold:
                        thresh = self.args.threshold
                    else:
                        thresh = 5 if self.args.type == 'deaths' else 100
                    start = False

                    # Modify x from cumulative per day starting at 0 to starting at threshold
                    x = [y_val for i, y_val in enumerate(y) if min(y[i:]) >= thresh]

                    # Create y as incremental cases per day
                    # TODO - will list comprehension apply here
                    y = x[:]
                    # y = [x0 - xp for x0, xp in (x, x[1:])]
                    for i in range(0, len(x)):
                        if i == 0:
                            y[i] = x[i] if x[i] > 0 else np.NaN
                        else:
                            y[i] = (x[i] - x[i-1]) if (x[i] - x[i-1]) > 0 else np.NaN

                    # Modify y to a moving average
                    # TODO - will list comprehension apply here
                    lookback = 3
                    y_orig = y[:]
                    for i in range(lookback, len(y)):
                        y[i] = float(np.nansum(y_orig[i-lookback: i]))/float(lookback - 1)

                    ax.plot(x, y, label=lname)
                    ax.text(x=x[-1], y=y[-1], s=pname,
                            bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)
                else:
                    ax.plot(y, label=lname)
                    ax.text(x=len(y), y=y[-1], s=pname,
                            bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)

        # plot the bar plot
        if self.args.response == 'growth':
            ax.grid(False)
            plt.xticks(rotation=90)
            ax.bar(np.arange(len(bar_y)), bar_y, tick_label=bar_l)
        else:
            ax.grid(True)
            ax.legend(loc="upper left", fontsize=8)

        # Now add details to the plot
        name_1 = 'Confirmed' if self.args.type == 'confirmed' else 'Deaths'
        name_2 = 'Growth' if self.args.response == 'growth' else 'Cases'
        y_axis_l = 'Highest Last 3 Day Median Growth' if self.args.response == 'growth' else 'Days Since Outbreak'
        data_desc = 'Top {} {} for regions, threshold = {} {} cases'.format(self.args.length, name_2,
                                                                            self.args.threshold, name_1)
        if self.args.region == 'country':
            name_region = 'Country'
            x_tick_adjust = 0.25 if self.args.response == 'growth' else 0.1
        elif self.args.region == 'state' or self.args.region == 'province':
            ps = 'State' if self.args.country == 'US' else 'Province/State'
            name_region = '{} for {}'.format(ps, self.args.country)
            if self.args.country == 'US':
                x_tick_adjust = 0.15 if self.args.response == 'growth' else 0.1
            else:
                x_tick_adjust = 0.32 if self.args.response == 'growth' else 0.1
        elif self.args.region == 'county-state':
            name_region = '{} {}'.format('US', 'County, State')
            x_tick_adjust = 0.32 if self.args.response == 'growth' else 0.1
        else:
            state_name = ussa.abbrev_us_state[self.args.state]
            name_region = 'County for {}'.format(state_name)
            x_tick_adjust = 0.28 if self.args.response == 'growth' else 0.1

        plt.figtext(0.99, 0.01, '{}\n{}\nAnalytics: {}'.format(data_desc, credit_str, self._analytics_source),
                    horizontalalignment='right', fontsize=8)
        fig.subplots_adjust(bottom=x_tick_adjust)
        ax.set_title('COVID-19 {} {} by {}'.format(name_1, name_2, name_region), fontsize=20)
        if self.args.response == 'new-total':
            plt.ylabel('New {}'.format(self.args.type), fontsize=16)
            plt.xlabel('Total {}'.format(self.args.type), fontsize=16)
        else:
            plt.ylabel('{} {}'.format(name_1, name_2), fontsize=16)
            plt.xlabel(y_axis_l, fontsize=16)

        # Output plot
        if self.args.saveplot:
            plt.savefig(plot_fname, quality=90, optimize=True)
        if self.args.showplot:
            plt.show()


def main():
    """
    Main flow for covid19-vi.
    :return: None
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('--about', help='display information about this utility',
                        action='store_true', default=False)
    parser.add_argument('--length', help='data length for sorted reports',
                        type=int, default=10)
    parser.add_argument('--threshold', help='threshold of case number to be included',
                        type=int, default=None)
    parser.add_argument('--country', help='name of country for state/province reports',
                        type=str, default='US')
    parser.add_argument('--state', help='name of state for county reports',
                        type=str, default='NY')
    parser.add_argument('--region', help='scope of report: country, state, province, county, county-state',
                        type=str, default='country')
    parser.add_argument('--type', help='type of report: confirmed, deaths',
                        type=str, default='confirmed')
    parser.add_argument('--response', help='response: log, linear, growth, new-total',
                        type=str, default='log')
    parser.add_argument('--sources', help='list sources used by this utility',
                        action='store_true', default=False)
    parser.add_argument('--download', help='download data from sources and save local pickle',
                        action='store_true', default=False)
    parser.add_argument('--saveplot', help='save plot output to a file',
                        action='store_true', default=False)
    parser.add_argument('--showplot', help='plot output',
                        action='store_true', default=False)
    parser.add_argument('--savetable', help='write table to file',
                        action='store_true', default=False)
    parser.add_argument('--showtable', help='display table',
                        action='store_true', default=False)
    parser.add_argument('--savedir', help='destination for saving output',
                        type=str, default=None)
    parser.add_argument('--debug', help='debug output',
                        action='store_true', default=False)
    args = parser.parse_args()

    # About me
    if args.about:
        print(__doc__)
        print('Author: ', __author__)
        print('Copyright: ', __copyright__)
        print('Credits: ', __credits__)
        print('License: ', __license__)
        print('Version: ', __version__)
        print('Maintainer: ', __maintainer__)
        print('Status: ', __status__)
        print('')
        CovidData.print_args()
        print('')
        sys.exit(0)

    if not CovidData.chk_args():
        print('Error: invalid arguments.')
        sys.exit(-10)

    plot = True if args.showplot or args.saveplot else False
    table = True if args.showtable or args.savetable else False

    covid_data = CovidData(args=args, download=args.download)

    if args.sources:
        covid_data.print_sources()

    if table or plot:
        covid_data.top_ten(plot=plot)

    sys.exit(0)


if __name__ == '__main__':
    main()
