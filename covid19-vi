#!/usr/bin/env python3
""" covid19-vi  -  Visualization utilities for the COVID-19 data from Johns Hopkins.

    Copyright (C) 2020  Natalya Langford

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""
__author__ = 'Natalya Langford'
__copyright__ = 'Copyright (C) 2020 Natalya Langford'
__credits__ = ['']
__license__ = 'GNU General Public License'
__program_name__ = 'covid19-vi'
__version__ = 'v0.0.1'
__maintainer__ = 'Natalya Langford'
__status__ = 'Under Development'
__docformat__ = 'reStructuredText'
# pylint: disable=multiple-statements
# pylint: disable=line-too-long

import argparse
import sys
import os
from datetime import datetime
import shutil
import pickle
import urllib.request
import us_state_abbrev as ussa
import pandas as pd
import numpy as np


class CovidData:
    _covid_data = {'confirmed': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv',
                   'deaths': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv',
                   'recoveries': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv'}
    _pickle_filename = 'covid_data.pickle'
    _prov_state_countries = ['US', 'China', 'Canada', 'Australia']

    def __init__(self, download=False):
        """
        Initialize a CovidData object and populate from interweb if download is True.
        :param download:
        :type download: Bool
        :return None
        """
        self.data = {'download_date': None, 'confirmed': None, 'deaths': None, 'recoveries': None}
        self.read_datafile(download=download)

    def print_sources(self):
        """
        :return: None
        """
        [print('{}: {}'.format(k, v)) for k, v in self._covid_data.items()]

    def read_datafile(self, download=False):
        """
        Read covid-19 data from the repository datafiles or a pickle file depends on value of download.
        Source: https://github.com/Ricks-Lab/amdgpu-utils/blob/c10dba61f11b9e5fb44d24acd1fa74122668afc2/GPUmodules/PCImodule.py

        :param download: Dowload from the interweb if True, else read pickled data.
        :type download: bool
        :return: bool
        """
        if not download and os.path.isfile(self._pickle_filename):
            # Read pickle file.
            with open(self._pickle_filename, 'rb') as f:
                self.data = pickle.load(f)
            return True

        for report_key in self._covid_data.keys():
            temp_file_name = 'covid_{}_{}.csv'.format(report_key, datetime.utcnow().strftime('%m%d_%H%M%S'))
            # temp_file_name = 'covid_{}_{}.csv'.format(report_key, 'test')
            with urllib.request.urlopen(self._covid_data[report_key]) as response, open(temp_file_name, 'wb') as out_file:
                shutil.copyfileobj(response, out_file)
            self.data[report_key] = self.read_csv_file(temp_file_name)
            os.remove(temp_file_name)
        self.data['download_date'] = datetime.utcnow()

        # Save pickle file.
        with open(self._pickle_filename, 'wb') as f:
            pickle.dump(self.data, f)

        return True

    @staticmethod
    def aggregate_state_prov(df, country):
        sp_df = df.loc[df['Country/Region'] == country]
        country_df = sp_df.head(1)
        country_df.loc[:, 5:] = sp_df.values[:, 5:].sum(axis=0)
        country_df['Province/State'] = np.NaN
        fdf = pd.concat([df, country_df], ignore_index=True)
        return fdf

    def read_csv_file(self, file_name):
        """
        Read and preprocess the csv data files.  Format is from Johns Hopkins GitHub repo.
        :param file_name: File name of the csv file to be processed.
        :return: list
        """
        df = pd.read_csv(file_name)
        df['total'] = df.values[:, -1]
        for country in self._prov_state_countries:
            df = self.aggregate_state_prov(df, country)
        df.loc[df['Province/State'] == df['Country/Region'], 'Province/State'] = np.NaN
        df.loc[df['Country/Region'] == 'Taiwan*', 'Country/Region'] = 'Taiwan'
        return df

    def top_ten(self, number=10, report_name='country', report_key='confirmed', state='New York', country='US'):
        """
         Generate tabular data report.
        :param number: Number of lines of data for the table.
        :type number: int
        :param report_name:
        :type report_name: str
        :param report_key:
        :type report_key: str
        :param state:
        :type state: str
        :param country:
        :type country: str
        :return: None
        """
        # TODO - display age of data.
        print('Top {} Report - {}'.format(report_name, report_key))
        print('  Extract downloaded: {} UTC'.format(self.data['download_date']))
        if report_name == 'country':
            # TODO drop the Province/State column
            tdf = self.data[report_key].loc[self.data[report_key]['Province/State'].isnull()]
            ttdf = tdf.sort_values(['total'], ascending=False).head(number)
        elif report_name == 'state' or report_name == 'province':
            # TODO Indicate total for the Country entry
            ldf = self.data[report_key].loc[self.data[report_key]['Country/Region'] == country]
            regex_pattern = r'.*, [A-Z][A-Z]'  # This regex represents US County entries.
            ldf = ldf[~ldf['Province/State'].str.contains(regex_pattern, na=False)]
            ttdf = ldf.sort_values(['total'], ascending=False).head(number)
        elif report_name == 'us-county':
            state_abv = ussa.us_state_abbrev[state]
            state_abv_str = ', {}'.format(state_abv)
            usdf = self.data[report_key].loc[self.data[report_key]['Country/Region'] == 'US']
            df1 = usdf.loc[usdf['Province/State'] == state]
            df2 = usdf.query('`Province/State`.str.endswith(@state_abv_str, na=False)')
            stdf = pd.concat([df1, df2], ignore_index=True)
            ttdf = stdf.sort_values(['total'], ascending=False).head(number)
        else:
            print('Error: Invalid report specified.')
            sys.exit(-1)
        with pd.option_context('display.max_rows', None, 'show_dimensions',  False):
            ttdf.reset_index(drop=True, inplace=True)
            print(ttdf)
        print('')


def main():
    """
    Main flow for covid19-vi.
    :return: None
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('--about', help='README',
                        action='store_true', default=False)
    parser.add_argument('--length', help='length of sorted reports',
                        type=int, default=10)
    parser.add_argument('--country', help='Name of country for state/province report.',
                        type=str, default='US')
    parser.add_argument('--state', help='Name of state for county report.',
                        type=str, default='New York')
    parser.add_argument('--report', help='country, state, province, us-county',
                        type=str, default='confirmed')
    parser.add_argument('--parameter', help='confirmed, deaths, recoveries',
                        type=str, default='confirmed')
    parser.add_argument('--download', help='download csv file',
                        action='store_true', default=False)
    parser.add_argument('--filename', help='csv file name',
                        type=str, default='')
    parser.add_argument('--table', help='Output table of basic GPU details',
                        action='store_true', default=False)
    parser.add_argument('-d', '--debug', help='Debug output',
                        action='store_true', default=False)
    args = parser.parse_args()

    # About me
    if args.about:
        print(__doc__)
        print('Author: ', __author__)
        print('Copyright: ', __copyright__)
        print('Credits: ', __credits__)
        print('License: ', __license__)
        print('Version: ', __version__)
        print('Maintainer: ', __maintainer__)
        print('Status: ', __status__)
        sys.exit(0)

    covid_data = CovidData(download=args.download)

    covid_data.top_ten(number=args.length, report_name=args.report, report_key=args.parameter,
                       state=args.state, country=args.country)

    sys.exit(0)


if __name__ == '__main__':
    main()
