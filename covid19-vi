#!/usr/bin/env python3
""" covid19-vi  -  Visualization utilities for the COVID-19 data from Johns Hopkins.

    The *covid19-vi* utility is the main interface for the projects access to the public COVID-19
    time series data.  The *--download* option is used to retrieve the latest data from the
    sources defined in the project. The data is read with a url request and loaded into a
    dataframe.  The dataframe is processed with error checkers, aggretators, and analytics
    utilities and then pickled for quicker use by the utility.

    Copyright (C) 2020  Natalya Langford

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""
__author__ = 'Natalya Langford'
__copyright__ = 'Copyright (C) 2020 Natalya Langford'
__credits__ = ['Ricks-Lab - Collaborator']
__license__ = 'GNU General Public License'
__program_name__ = 'covid19-vi'
__version__ = 'v0.0.1'
__maintainer__ = 'Natalya Langford'
__status__ = 'Under Development'
__docformat__ = 'reStructuredText'
# pylint: disable=multiple-statements
# pylint: disable=line-too-long

import argparse
import sys
import re
import os
from datetime import datetime
import io
import pickle
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import us_state_abbrev as ussa


class CovidData:
    """
    Class for downloading, processing, and reporting on COVID-19 time series data.
    """
    _covid_data = {'global': {'confirmed': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',
                              'deaths': 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'},
                   'usa': {'confirmed': 'https://static.usafacts.org/public/data/covid-19/covid_confirmed_usafacts.csv',
                           'deaths': 'https://static.usafacts.org/public/data/covid-19/covid_deaths_usafacts.csv'}}
    _pickle_filename = 'covid_data.pickle'
    _prov_state_countries = ['China', 'Canada', 'Australia', 'France', 'United Kingdom', 'Netherlands', 'Denmark']
    _data_source = {'global': {'link': 'https://github.com/CSSEGISandData/COVID-19',
                               'name': 'Johns Hopkins University'},
                    'usa': {'link': 'https://usafacts.org/issues/coronavirus/',
                            'name': 'USA Facts'}}
    _analytics_source = 'https://github.com/natalyalangford/COVID19_plots'
    _valid_args = {'type': ['deaths', 'confirmed'],
                   'region': ['country', 'state', 'province', 'county', 'county-state'],
                   'response': ['log', 'linear', 'growth', 'new-total', 'trajectory']}

    def __init__(self, args, download=False):
        """
        Initialize a CovidData object and populate from interweb if download is True.
        :param download: Flag to force actual download instead of using pickled data.
        :type download: Bool
        :return None
        """
        self.data = {'global': {'data_date': None,
                                'download_date': None,
                                'confirmed': None,
                                'deaths': None,
                                'recoveries': None},
                     'usa': {'data_date': None,
                             'download_date': None,
                             'confirmed': None,
                             'deaths': None,
                             'recoveries': None}}
        self.args = args
        if not self.read_datafile(download=download):
            print('Error: error while downloading sources.')
            sys.exit(-20)

    @classmethod
    def chk_args(cls, args):
        """
        Argument error checking used by this utility.
        :param args: args from args.parser
        :return: True if check passes else False
        :rtype: bool
        """
        if args.dsw < 1:
            print('Error in value for --dsw {}, must be an integer > 0.'.format(args.dsw))
            return False
        if args.threshold:
            if args.threshold <= 0:
                print('Error in value for --threshold {}, must be a positive integer.'.format(args.threshold))
                return False
        if args.response not in cls._valid_args['response']:
            print('Error in value for --response {}, valid values are {}'.format(args.response,
                                                                                 cls._valid_args['response']))
            return False
        if args.type not in cls._valid_args['type']:
            print('Error in value for --type {}, valid values are {}'.format(args.type,
                                                                             cls._valid_args['type']))
            return False
        if args.region not in cls._valid_args['region']:
            print('Error in value for --region {}, valid values are {}'.format(args.region,
                                                                               cls._valid_args['region']))
            return False
        if args.state not in ussa.us_state_abbrev.values():
            print('Error in value for --state {}, {} is not a valid US state abbreviation'.format(args.state,
                                                                                                  args.state))
            print('Valid state abbreviations: {}'.format(list(ussa.abbrev_us_state.keys())))
            return False
        if args.length <= 0:
            print('Error in value for --length {}, must be positive integer.'.format(args.length))
            return False
        if args.savedir:
            if re.search(r'[\\/?%*:|\"<>]', args.savedir):
                print('Error in value for --savedir {}, contains invalid characters'.format(args.savedir))
                return False
            if re.search(r'[\s]', args.savedir):
                print('Error in value for --savedir ',
                      '{}, there is a special place in hell for people who use spaces in directory names.'.format(
                          args.savedir))
                return False
        return True

    @classmethod
    def print_args(cls):
        """
        Prints valid arguments for command line options that require a string.
        :return:
        """
        print('Valid argument values:')
        [print(' {}: {}'.format(k2, v2)) for k2, v2 in cls._valid_args.items()]

    @classmethod
    def print_sources(cls):
        """
        Formatted print of data sources used by this utility.
        :return: None
        """
        for k, v in cls._covid_data.items():
            print(k)
            [print(' {}: {}'.format(k2, v2)) for k2, v2 in v.items()]

    def read_datafile(self, download=False):
        """
        Read covid-19 data from the repository datafiles or a pickle file depends on value of download.
        Source: https://github.com/Ricks-Lab/amdgpu-utils/blob/c10dba61f11b9e5fb44d24acd1fa74122668afc2/GPUmodules/PCImodule.py

        :param download: Download from the interweb if True, else read pickled data.
        :type download: bool
        :return: bool
        """
        if not download and os.path.isfile(self._pickle_filename):
            # Read pickle file.
            with open(self._pickle_filename, 'rb') as f:
                self.data = pickle.load(f)
            return True

        for zone, zone_dict in self._covid_data.items():
            #if zone == 'global': continue
            for report_type, link in zone_dict.items():
                print('Downloading: Zone: {}, Type: {}'.format(zone, report_type))
                if self.args.debug:
                    temp_file_name = 'covid_{}_{}_{}.csv'.format(zone, report_type, 'test')
                else:
                    temp_file_name = 'covid_{}_{}_{}.csv'.format(zone, report_type,
                                                                 datetime.utcnow().strftime('%m%d_%H%M%S'))
                if not self.args.debug or not os.path.isfile(temp_file_name):
                    try:
                        csv_data = requests.get(link).content
                    except requests.exceptions.RequestException as err:
                        print('Error [{}]: could not download:\n   [{}].'.format(err, link))
                        continue
                read_df = pd.read_csv(io.StringIO(csv_data.decode('utf-8', errors='replace')), sep=',')
                # Delete unnamed columns
                read_df = read_df.loc[:, ~read_df.columns.str.contains('^Unnamed')]
                if zone == 'usa':
                    # Delete rows with null state or county name
                    read_df = read_df.loc[(~read_df['County Name'].isnull() | ~read_df['State'].isnull())].copy()
                if self.args.debug:
                    with pd.option_context('display.max_rows', None, 'show_dimensions', False):
                        print(read_df.head(1))
                self.data[zone][report_type] = self.read_csv_file(csv_data, zone, read_df)
                self.data[zone]['data_date'] = self.data[zone][report_type].columns[-5]
                print('  Last data date: {}, Data size: {}'.format(self.data[zone]['data_date'], read_df.shape))
            self.data[zone]['download_date'] = datetime.utcnow()

        # Save pickle file.
        with open(self._pickle_filename, 'wb') as f:
            pickle.dump(self.data, f)

        return True

    @staticmethod
    def aggregate_world(df):
        """
        Aggregate global total from country level data.
        :param df: Target dataframe
        :type df: pandas.core.frame.DataFrame
        :return: Dataframe with aggregation row added
        :rtype: pandas.core.frame.DataFrame
        """
        ac_df = df.loc[df['Province/State'].isnull()].copy()
        ac_df.iloc[:, 5:] = ac_df.iloc[:, 5:].fillna(0)
        world_df = ac_df.head(1).copy()
        world_df.iloc[:, 5:] = ac_df.values[:, 5:].sum(axis=0)
        world_df.loc[:, 'Country/Region'] = 'Global'
        world_df.loc[:, 'Province/State'] = np.NaN
        world_df.loc[:, 'Lat'] = 0.0
        world_df.loc[:, 'Long'] = 0.0
        fdf = pd.concat([df, world_df], ignore_index=True)
        return fdf

    @staticmethod
    def aggregate_state_prov(df, target_country):
        """
        Aggregate state/province level data to country totals.
        :param df: Target dataframe
        :type df: pandas.core.frame.DataFrame
        :param target_country: Country for aggregation
        :type target_country: str
        :return: dataframe with aggregation row added
        :rtype: pandas.core.frame.DataFrame
        """
        if target_country == 'US':
            fdf = df.copy()
            state_list = df['State'].unique()
            # TODO - Need to replace with pivot
            for state in state_list:
                sc_df = df.loc[df['State'] == state, :].copy()
                state_df = sc_df.head(1).copy()
                state_df.loc[0, 4:] = 0
                sc_df.iloc[:, 4:] = sc_df.iloc[:, 4:].fillna(0)
                state_df.loc[:, 4:] = sc_df.values[:, 4:].sum(axis=0)
                state_df = state_df.head(1).copy()
                state_df.loc[:, 'County Name'] = np.NaN
                fdf = pd.concat([fdf, state_df], ignore_index=True)
        else:
            sp_df = df.loc[df['Country/Region'] == target_country, :].copy()
            sp_df.iloc[:, 5:] = sp_df.iloc[:, 5:].fillna(0)
            country_df = sp_df.head(1).copy()
            country_df.loc[:, 5:] = sp_df.values[:, 5:].sum(axis=0)
            country_df.loc[:, 'Province/State'] = np.NaN
            fdf = pd.concat([df, country_df], ignore_index=True)
        return fdf

    def read_csv_file(self, file_name, zone, df=None):
        """
        Read and pre-process the csv data files.  Format is from Johns Hopkins GitHub repo.
        :param file_name: File name of the csv file to be processed.
        :type file_name: str
        :param zone: global or usa file source.
        :type zone: str
        :param df: dataframe to use instead of reading csv file.
        :type df: pandas.core.frame.DataFrame
        :return: list
        """
        if df is None:
            try:
                df = pd.read_csv(file_name)
            except UnicodeDecodeError:
                df = pd.read_csv(file_name, encoding='ISO-8859-1')

        if zone == 'global':
            for ps_country in self._prov_state_countries:
                df.loc[(df['Province/State'].isna()) & (df['Country/Region'] == ps_country),
                       'Province/State'] = ps_country
                df = self.aggregate_state_prov(df, ps_country)
            df = self.aggregate_world(df)
            df.loc[df['Country/Region'] == 'Taiwan*', 'Country/Region'] = 'Taiwan'
        else:
            df = self.aggregate_state_prov(df, 'US')
        # TODO - add days to double metric
        df.loc[:, 'Yesterday'] = df.iloc[:, -2]
        df.loc[:, 'Total'] = df.iloc[:, -2]
        df.loc[:, 'DayIncrease'] = df.loc[:, 'Total'] - df.loc[:, 'Yesterday']
        df.loc[:, '%DayIncrease'] = (df.loc[:, 'DayIncrease'] / df.loc[:, 'Yesterday'])
        df.loc[df['%DayIncrease'].isna(), '%DayIncrease'] = 0.0
        df.loc[:, '%DayIncrease'] = round(100.0 * df.loc[:, '%DayIncrease'], 1)
        return df

    def day_percent_growth(self, df, file_zone):
        """
        Calculate daily percentage growth based on past growth numbers, and populate Median with dsw day median.
        :param df: target dataset
        :type df: pandas.core.frame.DataFrame
        :param file_zone: Zone for data: usa or global
        :type file_zone: str
        :return: New dataframe with cases replaced by growth percentage
        :rtype: pandas.core.frame.DataFrame
        """
        # TODO - Need regression fit to calculate rate of increase instead of 3 day median
        dpd_df = df.copy(deep=True)
        series_start = 4 if file_zone == 'usa' else 5
        series_end = df.shape[1] - 4
        dpd_df.iloc[:, series_start:series_end] = \
            (df.iloc[:, series_start:series_end].pct_change(axis=1) * 100.0).round(1)
        with pd.option_context('mode.use_inf_as_na', True):
            dpd_df.iloc[:, series_start:series_end] = dpd_df.iloc[:, series_start:series_end].fillna(0.0)
        dpd_df.loc[:, 'Cases'] = dpd_df.loc[:, 'Total']
        dpd_df.loc[:, 'Total'] = dpd_df.iloc[:, series_end - self.args.dsw:series_end].median(axis=1,
                                                                                              skipna=True,
                                                                                              numeric_only=True)
        dpd_df = dpd_df.rename(columns={'Total': 'Median'})
        dpd_df = dpd_df.drop('%DayIncrease', axis=1)
        dpd_df = dpd_df.drop('Yesterday', axis=1)
        dpd_df.reset_index(drop=True, inplace=True)
        dpd_df.loc[:, 'DayIncrease'] = dpd_df.iloc[:, -4] - dpd_df.iloc[:, -5]
        return dpd_df

    def report_process(self, rdf, glb_usa):
        """
        Prepare selected dataset for generation of plot/table reports.
        :param rdf: target dataset
        :type rdf: pandas.core.frame.DataFrame
        :param glb_usa: process as global or usa dataset
        :type glb_usa: str
        :return: new processed dataframe
        :rtype: pandas.core.frame.DataFrame
        """
        # Pre-process data
        #rdf = rdf.loc[rdf['Total'] >= self.args.threshold] if self.args.threshold else \
            #rdf.sort_values(['Total'], ascending=False).head(self.args.length)
        if self.args.threshold:
            rdf = rdf.loc[rdf['Total'] >= self.args.threshold]
        rdf.reset_index(drop=True, inplace=True)

        # Process for growth or number
        if self.args.response == 'growth':
            rdf.reset_index(drop=True, inplace=True)
            rdf = self.day_percent_growth(rdf, glb_usa)
            # rdf = rdf.sort_values(['Median'], ascending=False)
            rdf = rdf.sort_values(['Median'], ascending=False).head(self.args.length)
        else:
            rdf = rdf.sort_values(['Total'], ascending=False).head(self.args.length)
        return rdf

    def top_ten(self, plot=False):
        """
        Generate tabular data report.
        :param plot:  Flag to indicate if plot is requested.
        :type plot: bool
        :return: None
        """
        plot_file_name_suffix = 'png'
        table_file_name_suffix = 'txt'
        report_file_name = None
        table_df = plot_df = pd.DataFrame()
        if self.args.region == 'country':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, self.args.region, 'global', self.args.response)

            # Pre-process data
            temp_df = self.data['global'][self.args.type]
            tdf = temp_df.loc[temp_df['Province/State'].isnull()].copy()
            tdf = tdf.drop('Province/State', axis=1)
            tdf = self.report_process(tdf, 'global')

            # Set the plot data
            if plot:
                plot_df = tdf.copy()

            # Select columns for table
            num_cols = tdf.shape[1]
            col_select = np.r_[0:1, num_cols-11:num_cols]
            table_df = tdf.iloc[:, col_select]

        elif self.args.region == 'state' or self.args.region == 'province':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, self.args.region,
                                                    self.args.country, self.args.response)

            if self.args.country == 'US':
                # Pre-process data
                temp_df = self.data['usa'][self.args.type]
                tdf = temp_df.loc[temp_df['County Name'].isnull()].copy()
                tdf = self.report_process(tdf, 'usa')

                # Set the plot data
                if plot:
                    plot_df = tdf.copy()

                # Select columns for table
                num_cols = tdf.shape[1]
                col_select = np.r_[2, num_cols-10:num_cols]
                table_df = tdf.iloc[:, col_select]

            else:
                # Pre-process data
                tdf = self.data['global'][self.args.type]
                tdf = tdf.loc[tdf['Country/Region'] == self.args.country].copy()
                tdf.loc[(tdf['Province/State'].isna()), 'Province/State'] = 'Total'
                tdf = self.report_process(tdf, 'global')

                # Set the plot data
                if plot:
                    plot_df = tdf.copy()

                num_cols = tdf.shape[1]
                col_select = np.r_[0:2, num_cols-8:num_cols]
                table_df = tdf.iloc[:, col_select].copy()

        elif self.args.region == 'county':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, 'county', self.args.state, self.args.response)

            # Pre-process data
            temp_df = self.data['usa'][self.args.type]
            tdf = temp_df.loc[temp_df['State'] == self.args.state].copy()
            tdf.loc[(tdf['County Name'].isna()), 'County Name'] = 'Total'
            tdf = self.report_process(tdf, 'usa')

            # Set the plot data
            if plot:
                plot_df = tdf.copy()

            num_cols = tdf.shape[1]
            col_select = np.r_[1:3, num_cols-8:num_cols]
            table_df = tdf.iloc[:, col_select].copy()

        elif self.args.region == 'county-state':
            report_file_name = '{}_{}_{}_{}'.format(self.args.type, 'county-state',
                                                    self.args.country, self.args.response)

            # Pre-process data
            temp_df = self.data['usa'][self.args.type]
            tdf = temp_df.loc[~temp_df['County Name'].isnull()].copy()
            tdf = self.report_process(tdf, 'usa')

            # Set the plot data
            if plot:
                plot_df = tdf.copy()

            num_cols = tdf.shape[1]
            col_select = np.r_[1:3, num_cols - 8:num_cols]
            table_df = tdf.iloc[:, col_select].copy()

        else:
            print('Error: Invalid report specified.')
            sys.exit(-1)

        # Display and/or write report table.
        if self.args.showtable or self.args.savetable:
            file_ptr_list = [sys.stdout] if self.args.showtable else []
            table_file_name = '{}.{}'.format(report_file_name, table_file_name_suffix)
            if self.args.savedir:
                if not os.path.isdir(self.args.savedir):
                    os.mkdir(self.args.savedir, 0o775)
                table_file_name = os.path.join(self.args.savedir, table_file_name)
            if self.args.savetable: file_ptr_list.append(open(table_file_name, 'w'))
            for fp in file_ptr_list:
                # TODO - display age of data.
                name_1 = 'Confirmed' if self.args.type == 'confirmed' else 'Deaths'
                name_2 = 'Growth' if self.args.response == 'growth' else 'Cases'
                markup = ('\x1B[3m', '\x1B[23m') if fp == sys.stdout else ('', '')
                print('', file=fp)
                print('Top {} {} Report - {}'.format(self.args.length, self.args.region, self.args.type), file=fp)
                print('  Top {} {} for regions, threshold = {} {} cases'.format(self.args.length, name_2,
                                                                                self.args.threshold, name_1), file=fp)
                print('  Extract downloaded: {} UTC'.format(self.data['global']['download_date']), file=fp)
                print('  Data last data point date: {}'.format(self.data['global']['data_date']), file=fp)
                with pd.option_context('display.max_rows', None, 'show_dimensions', False):
                    table_df.reset_index(drop=True, inplace=True)
                    print(table_df, file=fp)
                print('', file=fp)
                data_src = 'usa' if self.args.region != 'country' and self.args.country == 'US' else 'global'
                credit_str = 'Data from the {} extract at {}, Credit: {}'.format(
                             self.data[data_src]['data_date'],
                             self._data_source[data_src]['link'],
                             self._data_source[data_src]['name'])
                print('{}   {}\n   Analytics: {}{}'.format(markup[0], credit_str, self._analytics_source,
                                                           markup[1]), file=fp)
                print('', file=fp)
                if fp != sys.stdout:
                    fp.close()

        # Display and/or write plot.
        if plot:
            plot_file_name = '{}.{}'.format(report_file_name, plot_file_name_suffix)
            if self.args.savedir:
                if not os.path.isdir(self.args.savedir):
                    os.mkdir(self.args.savedir, 0o775)
                plot_file_name = os.path.join(self.args.savedir, plot_file_name)
            self.plot(plot_df, plot_file_name)

    def plot(self, pdf, plot_fname):
        """
        Plot the target dataframe to file or display.
        :param pdf: Target dataframe
        :type pdf: pandas.core.frame.DataFrame
        :param plot_fname: Plot filename used if saveplot is specified.
        :type plot_fname: str
        :return: None
        """
        # Basic report parameters
        plot_response = 'Median' if self.args.response == 'growth' else 'Total'
        num_cols = pdf.shape[1]
        col_select = np.r_[4:num_cols-4]

        # Set credit string base on data source
        data_src = 'usa' if self.args.region != 'country' and self.args.country == 'US' else 'global'
        credit_str = 'Data from the {} extract at {}, Credit: {}'.format(
                     self.data[data_src]['data_date'],
                     self._data_source[data_src]['link'],
                     self._data_source[data_src]['name'])

        # Select label names based on report type and region
        if self.args.region == 'county-state':
            pdf.loc[:, 'County Name'] = pdf.loc[:, 'County Name'] + ', ' + pdf.loc[:, 'State']
            trunc_len = 25
        if self.args.region == 'country':
            col_select = np.r_[3:num_cols - 4]
            plot_item_names = list(pdf['Country/Region'])
            trunc_len = 15
        else:
            if self.args.country == 'US':
                plot_item_names = list(pdf['State']) if self.args.region == 'state' else list(pdf['County Name'])
                trunc_len = 5 if self.args.region == 'state' else 25
            else:
                plot_item_names = list(pdf['Province/State'])
                trunc_len = 25

        # Prepare matplotlib figure.
        fig = plt.figure(figsize=(10, 10))
        ax = fig.add_subplot(1, 1, 1)
        ax.set_facecolor('#d0dbd5')
        fig.patch.set_facecolor('#eeeeee')

        # Generate Plots
        bar_y = []
        bar_l = []
        max_days = 0
        max_cases = 0
        for pname in plot_item_names:
            # Get parameter values as y
            if self.args.region == 'country':
                y = pdf.loc[pdf['Country/Region'] == pname, :]
                total = pdf.loc[pdf['Country/Region'] == pname, plot_response].tolist()[0]
                bar_y.append(total)
            else:
                if self.args.country == 'US':
                    y = pdf.loc[pdf['State'] == pname, :] if self.args.region == 'state' else \
                        pdf.loc[pdf['County Name'] == pname, :]
                    total = pdf.loc[pdf['State'] == pname, plot_response].tolist()[0] if self.args.region == 'state' \
                            else pdf.loc[pdf['County Name'] == pname, plot_response].tolist()[0]
                    bar_y.append(total)
                else:
                    y = pdf.loc[pdf['Province/State'] == pname, :]
                    total = pdf.loc[pdf['Province/State'] == pname, plot_response].tolist()[0]
                    bar_y.append(total)
            y = list(y.iloc[0, col_select])

            # Construct legend name with values
            if isinstance(total, int):
                lname = '{} ({})'.format(pname[:trunc_len], total)
            else:
                lname = '{} ({})'.format(pname[:trunc_len], round(total, 1))
            if self.args.debug: print('{}\ny_raw = {}'.format(lname, y[:10]))

            # Plot lines and label or collect bar plot details for later
            if self.args.response == 'growth':
                # Just set label names, plot is after the loop
                bar_l.append('{}'.format(lname))
            elif self.args.response == 'new-total':
                x, y = self.plot_prep_new_total(y, self.args.dsw)
                if not len(x) or not len(y):
                    continue
                if self.args.debug: print('{}\nx = {}\ny = {}'.format(lname, x[:10], y[:10]))
                ax.set_yscale('log')
                ax.set_xscale('log')
                ax.plot(x, y, label=lname)
                ax.text(x=x[-1], y=y[-1], s=pname,
                        bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)
            elif self.args.response == 'trajectory':
                if self.args.threshold:
                    thresh = self.args.threshold
                else:
                    thresh = 5 if self.args.type == 'deaths' else 100
                if re.search('[G,g]lobal', pname) or re.search('China', pname) or re.search('Diamond Pri', pname):
                    continue
                y = self.start_at_threshold(y, thresh)
                if self.args.debug: print('{}: len: {}, y: {}'.format(pname, len(y), y))
                if len(y) < 10: continue
                max_days = len(y) if len(y) > max_days else max_days
                max_cases = max(y) if max(y) > max_cases else max_cases
                ax.set_yscale('log')
                ax.plot(y, label=lname)
                ax.text(x=len(y)-1, y=y[-1], s=pname,
                        bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)
            else:
                ax.set_yscale('log')
                ax.plot(y, label=lname)
                ax.text(x=len(y), y=y[-1], s=pname,
                        bbox=dict(boxstyle='round,pad=0.2', facecolor='#dddddd'), fontsize=6)

        # Finish plots
        name_1 = 'Confirmed' if self.args.type == 'confirmed' else 'Deaths'
        name_2 = 'Growth' if self.args.response == 'growth' else 'Cases'
        if self.args.response == 'growth':
            ax.grid(False)
            plt.xticks(rotation=90)
            ax.bar(np.arange(len(bar_y)), bar_y, tick_label=bar_l)
            plt.ylabel('{} {}'.format(name_1, name_2), fontsize=16)
            plt.xlabel('Highest Last {} Day Median Growth'.format(self.args.dsw), fontsize=16)
        elif self.args.response == 'trajectory':
            # Plot reference rate lines
            for d2d in [1, 2, 4, 7, 14]:
                ref_y = [100]
                for i in range(1, d2d*(20)):
                    ref_y.append(ref_y[0]*(2**(1/d2d))**i)
                lname = pname = '2x/{}Day'.format(d2d)
                ref_y = self.truncate_series(ref_y, max_days, max_cases)
                ax.plot(ref_y, label=lname, color='#444444', linestyle=':', linewidth=2)
                with plt.style.context({'text.color': '#ffffff'}):
                    ax.text(x=len(ref_y)-1, y=ref_y[-1], s=pname,
                            bbox=dict(boxstyle='round,pad=0.2', facecolor='#444444'), fontsize=6)
            plt.ylabel('{} {}'.format(name_1, name_2), fontsize=16)
            plt.xlabel('Days Since 100 {}'.format(name_1), fontsize=16)
            ax.grid(True)
        elif self.args.response == 'new-total':
            plt.ylabel('New {}'.format(name_1), fontsize=16)
            plt.xlabel('Total {}'.format(name_1), fontsize=16)
            ax.grid(True)
            ax.legend(loc="upper left", fontsize=8)
        else:
            plt.ylabel('{} {}'.format(name_1, name_2), fontsize=16)
            plt.xlabel('Days Since Outbreak', fontsize=16)
            ax.grid(True)
            ax.legend(loc="upper left", fontsize=8)

        # Now add details to the plot
        if self.args.region == 'country':
            name_region = 'Country'
            x_tick_adjust = 0.25 if self.args.response == 'growth' else 0.1
        elif self.args.region == 'state' or self.args.region == 'province':
            ps = 'State' if self.args.country == 'US' else 'Province/State'
            name_region = '{} for {}'.format(ps, self.args.country)
            if self.args.country == 'US':
                x_tick_adjust = 0.15 if self.args.response == 'growth' else 0.1
            else:
                x_tick_adjust = 0.32 if self.args.response == 'growth' else 0.1
        elif self.args.region == 'county-state':
            name_region = '{} {}'.format('US', 'County, State')
            x_tick_adjust = 0.32 if self.args.response == 'growth' else 0.1
        else:
            state_name = ussa.abbrev_us_state[self.args.state]
            name_region = 'County for {}'.format(state_name)
            x_tick_adjust = 0.28 if self.args.response == 'growth' else 0.1
        data_desc = 'Top {} {} for regions, threshold = {} {} cases'.format(self.args.length, name_2,
                                                                            self.args.threshold, name_1)
        plt.figtext(0.99, 0.01, '{}\n{}\nAnalytics: {}'.format(data_desc, credit_str, self._analytics_source),
                    horizontalalignment='right', fontsize=8)
        fig.subplots_adjust(bottom=x_tick_adjust)
        ax.set_title('COVID-19 {} {} by {}'.format(name_1, name_2, name_region), fontsize=20)

        # Output plot
        if self.args.saveplot:
            plt.savefig(plot_fname, quality=90, optimize=True)
        if self.args.showplot:
            plt.show()

    def plot_prep_new_total(self, y_list, lookback):
        """
        Prepare data for the new-total plot.
        :param y_list:
        :type y_list: list
        :param lookback: The size of the moving average window.
        :type lookback: int
        :return: tuple of x and y lists
        :rtype: tuple
        """
        if self.args.threshold:
            thresh = self.args.threshold
        else:
            thresh = 5 if self.args.type == 'deaths' else 100

        # Copy incoming list to y (new) and x (total
        x = y_list[:]
        y = y_list[:]

        # Get index for threshold
        start_index = self.threshold_index(y_list, thresh)

        # Create y as incremental cases per day
        y = self.total_to_increment(x)
        y = self.moving_average(y, lookback)
        return x[start_index:],  y[start_index:]

    @staticmethod
    def truncate_series(t_list, length, value):
        """
        Returns truncated list with max length and max values
        :param t_list: List of numbers
        :type t_list: list
        :param length: max list length
        :type length: int
        :param value: max value in a time series
        :type value: int
        :return: The resultant index or None is never met
        :rtype: list
        >>> CovidData.truncate_series([1, 2, 3, 4, 5, 6, 7], 4, 6)
        [1, 2, 3, 4]
        >>> CovidData.truncate_series([1, 2, 3, 4, 5, 6, 7], 6, 3)
        [1, 2, 3]
        >>> CovidData.truncate_series([1, 2, 3, 4, 5, 6, 7], 99, 99)
        [1, 2, 3, 4, 5, 6, 7]
        """
        if len(t_list) > length:
            t_list = t_list[0:length]
        i = len(t_list)
        for i, t_item in enumerate(t_list):
            if t_item >= value:
                break
        return t_list[:i+1]

    @staticmethod
    def threshold_index(t_list, threshold):
        """
        Return the index of the first item >= threshold
        :param t_list: List of numbers
        :type t_list: list
        :param threshold: The threshold
        :type threshold: int
        :return: The resultant index or None is never met
        :rtype: int
        >>> CovidData.threshold_index([1, 2, 3, 4, 5, 6, 7], 4)
        3
        >>> CovidData.threshold_index([1, 2, 3, 4, 5, 6, 7], 0)
        0
        >>> CovidData.threshold_index([1, 2, 3, 4, 5, 6, 7], 10)
        None

        # TODO Figure out why this test fails, got Nothing instead of None
        """
        for i, x in enumerate(t_list):
            if x >= threshold:
                return i
        return None

    @staticmethod
    def start_at_threshold(t_list, threshold):
        """
        Return a list that starts at the first item >= threshold
        :param t_list: List of numbers
        :type t_list: list
        :param threshold: The threshold
        :type threshold: int
        :return: The new list
        :rtype: list
        >>> CovidData.start_at_threshold([1, 2, 3, 4, 5, 6, 7], 4)
        [4, 5, 6, 7]
        >>> CovidData.start_at_threshold([1, 2, 3, 4, 5, 6, 7], 0)
        [1, 2, 3, 4, 5, 6, 7]
        >>> CovidData.start_at_threshold([1, 2, 3, 4, 5, 6, 7], 10)
        []
        """
        return [y_val for i, y_val in enumerate(t_list) if min(t_list[i:]) >= threshold]

    @staticmethod
    def moving_average(list_values, lookback):
        """
        Return a list that is the moving average of the original list with windows size of lookback
        :param list_values: List of numbers
        :type list_values: list
        :param lookback: Size of the window
        :type lookback: int
        :return: The new list
        :rtype: list
        >>> CovidData.moving_average([0, 654, 287, 493, 684, 809, 2651, 588, 2068, 1693], 2)
        [0, 327.0, 470.5, 390.0, 588.5, 746.5, 1730.0, 1619.5, 1328.0, 1880.5]
        >>> CovidData.moving_average([0, 654, 287, 493, 684, 809, 2651, 588, 2068, 1693], 3)
        [0, 327.0, 313.67, 478.0, 488.0, 662.0, 1381.33, 1349.33, 1769.0, 1449.67]
        """
        # TODO Needs testing
        list_new = list_values[:]
        for i in range(lookback - 1, len(list_values)):
            win_e = i + 1
            win_s = i - (lookback - 1)
            list_new[i] = round(float(np.nansum(list_values[win_s: win_e])) / float(lookback), 2)
        for i in range(1, lookback - 1):
            win_e = i + 1
            list_new[i] = round(float(np.nansum(list_values[0: win_e])) / float(i+1), 2)
        return list_new

    @staticmethod
    def total_to_increment(list_orig):
        """
        Return a list that is the difference of subsequent items with the first item set to NAN
        :param list_orig: List of numbers
        :type list_orig: list
        :return: The new list
        :rtype: list
        >>> CovidData.total_to_increment([0, 654, 941, 1434, 2118, 2927, 5578, 6166, 8234, 9927])
        [nan, 654, 287, 493, 684, 809, 2651, 588, 2068, 1693]
        >>> CovidData.total_to_increment([0, 654, 941, 1434, 2118, 2000, 5578, 6166, 8234, 9927])
        [nan, 654, 287, 493, 684, -118, 3578, 588, 2068, 1693]
        """
        list_new = list_orig[:]
        for i in range(0, len(list_orig)):
            if i == 0:
                list_new[i] = list_orig[i] if list_orig[i] > 0 else np.NaN
            else:
                list_new[i] = (list_orig[i] - list_orig[i - 1])
        return list_new


def main():
    """
    Main flow for covid19-vi.
    :return: None
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('--about', help='display information about this utility',
                        action='store_true', default=False)
    parser.add_argument('--length', help='data length for sorted reports',
                        type=int, default=10)
    parser.add_argument('--threshold', help='threshold of case number to be included',
                        type=int, default=None)
    parser.add_argument('--dsw', help='size of data smoothing window',
                        type=int, default=3)
    parser.add_argument('--country', help='name of country for state/province reports',
                        type=str, default='US')
    parser.add_argument('--state', help='name of state for county reports',
                        type=str, default='NY')
    parser.add_argument('--region', help='scope of report: country, state, province, county, county-state',
                        type=str, default='country')
    parser.add_argument('--type', help='type of report: confirmed, deaths',
                        type=str, default='confirmed')
    parser.add_argument('--response', help='response: log, linear, growth, new-total, trajectory',
                        type=str, default='log')
    parser.add_argument('--sources', help='list sources used by this utility',
                        action='store_true', default=False)
    parser.add_argument('--download', help='download data from sources and save local pickle',
                        action='store_true', default=False)
    parser.add_argument('--saveplot', help='save plot output to a file',
                        action='store_true', default=False)
    parser.add_argument('--showplot', help='plot output',
                        action='store_true', default=False)
    parser.add_argument('--savetable', help='write table to file',
                        action='store_true', default=False)
    parser.add_argument('--showtable', help='display table',
                        action='store_true', default=False)
    parser.add_argument('--savedir', help='destination for saving output',
                        type=str, default=None)
    parser.add_argument('--debug', help='debug output',
                        action='store_true', default=False)
    args = parser.parse_args()

    # About me
    if args.about:
        print(__doc__)
        print('Author: ', __author__)
        print('Copyright: ', __copyright__)
        print('Credits: ', __credits__)
        print('License: ', __license__)
        print('Version: ', __version__)
        print('Maintainer: ', __maintainer__)
        print('Status: ', __status__)
        print('')
        CovidData.print_args()
        print('')
        sys.exit(0)

    if not CovidData.chk_args(args):
        print('Error: invalid arguments.')
        sys.exit(-10)

    if args.sources:
        CovidData.print_sources()

    plot = True if args.showplot or args.saveplot else False
    table = True if args.showtable or args.savetable else False

    covid_data = CovidData(args=args, download=args.download)

    if table or plot:
        covid_data.top_ten(plot=plot)

    sys.exit(0)


if __name__ == '__main__':
    main()
    # import doctest
    # doctest.testmod()
